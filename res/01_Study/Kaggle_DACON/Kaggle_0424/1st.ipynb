{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패키지 불러오기\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터 읽기\n",
    "df = pd.read_csv(\"./data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>Many people have car where they live. The thin...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>I am a scientist at NASA that is discussing th...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>People always wish they had the same technolog...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001bdc0</td>\n",
       "      <td>We all heard about Venus, the planet without a...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002ba53</td>\n",
       "      <td>Dear, State Senator\\n\\nThis is a letter to arg...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id                                          full_text  score\n",
       "0  000d118  Many people have car where they live. The thin...      3\n",
       "1  000fe60  I am a scientist at NASA that is discussing th...      3\n",
       "2  001ab80  People always wish they had the same technolog...      4\n",
       "3  001bdc0  We all heard about Venus, the planet without a...      4\n",
       "4  002ba53  Dear, State Senator\\n\\nThis is a letter to arg...      3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터프레임 상위 5행 출력\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17307, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터프레임 크기\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    6280\n",
       "2    4723\n",
       "4    3926\n",
       "1    1252\n",
       "5     970\n",
       "6     156\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score(점수) 점수 개수 확인\n",
    "df['score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요없는 id 컬럼 삭제\n",
    "df.drop('essay_id', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    17307.000000\n",
       "mean      2071.617265\n",
       "std        925.910701\n",
       "min        712.000000\n",
       "25%       1397.000000\n",
       "50%       1924.000000\n",
       "75%       2541.000000\n",
       "max      20459.000000\n",
       "Name: full_text, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문자열 길이 확인\n",
    "df['full_text'].str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 21:43:50.118580: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-26 21:43:50.118603: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-26 21:43:50.119237: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-26 21:43:50.122858: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-26 21:43:50.596461: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# 문자열 전처리를 위한 패키지 로드\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import nltk, re, contractions\n",
    "from nltk.corpus import stopwords as stw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/yjg1005/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# 불용어 다운로드\n",
    "nltk.download(\"stopwords\")\n",
    "stopwords = list(stw.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 약어, 이메일주소, 태그문등 불필요한 데이터 제거\n",
    "reviews = []\n",
    "\n",
    "for i in df['full_text'].values:\n",
    "    # 불용어 처리\n",
    "    source = \" \".join([w for w in i.split() if w not in stopwords])\n",
    "\n",
    "    # 약어 처리\n",
    "    source = contractions.fix(source)\n",
    "\n",
    "    # email 제거\n",
    "    source = re.sub(\n",
    "            r\"\\b[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\\b\", \"\", source\n",
    "        )\n",
    "\n",
    "    # html 태그 제거\n",
    "    source = re.sub(r\"<[^>]*>\", \"\", source)\n",
    "\n",
    "    # url 제거\n",
    "    source = re.sub(\n",
    "            r\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\",\n",
    "            \"\",\n",
    "            source,\n",
    "        )\n",
    "\n",
    "    # 숫자 제거\n",
    "    source = re.sub(r\"\\b[0-9]+\\b\", \"\", source)\n",
    "\n",
    "    # 특수문자 제거\n",
    "    x = re.sub(r\"[^\\w ]+\", \"\", source)\n",
    "    source = \" \".join(x.split())\n",
    "    \n",
    "    reviews.append(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "      <th>pp_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Many people have car where they live. The thin...</td>\n",
       "      <td>3</td>\n",
       "      <td>Many people car live The thing know use car al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am a scientist at NASA that is discussing th...</td>\n",
       "      <td>3</td>\n",
       "      <td>I scientist NASA discussing face mars I explai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>People always wish they had the same technolog...</td>\n",
       "      <td>4</td>\n",
       "      <td>People always wish technology seen movies best...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We all heard about Venus, the planet without a...</td>\n",
       "      <td>4</td>\n",
       "      <td>We heard Venus planet without almost oxygen ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dear, State Senator\\n\\nThis is a letter to arg...</td>\n",
       "      <td>3</td>\n",
       "      <td>Dear State Senator This letter argue favor kee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  score  \\\n",
       "0  Many people have car where they live. The thin...      3   \n",
       "1  I am a scientist at NASA that is discussing th...      3   \n",
       "2  People always wish they had the same technolog...      4   \n",
       "3  We all heard about Venus, the planet without a...      4   \n",
       "4  Dear, State Senator\\n\\nThis is a letter to arg...      3   \n",
       "\n",
       "                                             pp_text  \n",
       "0  Many people car live The thing know use car al...  \n",
       "1  I scientist NASA discussing face mars I explai...  \n",
       "2  People always wish technology seen movies best...  \n",
       "3  We heard Venus planet without almost oxygen ea...  \n",
       "4  Dear State Senator This letter argue favor kee...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pp_text'] = reviews\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['pp_text']\n",
    "Y = df['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 단어 수 : 75336\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 토큰화\n",
    "tokenizer = Tokenizer(oov_token = '<OOV>')\n",
    "tokenizer.fit_on_texts(X)\n",
    "print(f\"전체 단어 수 : {len(tokenizer.word_index) + 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토큰의 크기 : 17307\n"
     ]
    }
   ],
   "source": [
    "token_set = tokenizer.texts_to_sequences(X)\n",
    "print(\"토큰의 크기 :\", len(token_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>would</td>\n",
       "      <td>46107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the</td>\n",
       "      <td>44989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>cars</td>\n",
       "      <td>43603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>people</td>\n",
       "      <td>38898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>car</td>\n",
       "      <td>37527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>i</td>\n",
       "      <td>35177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>venus</td>\n",
       "      <td>34968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>could</td>\n",
       "      <td>30035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>like</td>\n",
       "      <td>24165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>it</td>\n",
       "      <td>23200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  counts\n",
       "208   would   46107\n",
       "4       the   44989\n",
       "92     cars   43603\n",
       "1    people   38898\n",
       "2       car   37527\n",
       "97        i   35177\n",
       "402   venus   34968\n",
       "194   could   30035\n",
       "10     like   24165\n",
       "137      it   23200"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 빈도 확인\n",
    "bins = tokenizer.word_counts.items()\n",
    "pd.DataFrame(bins, columns = ['word', 'counts']).sort_values('counts', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 75335\n",
      "등장 빈도가 30번 미만인 희귀 단어의 수: 70029\n",
      "단어 집합에서 희귀 단어의 비율: 92.9567929913055\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 5.193031112076686\n",
      "단어 집합의 크기 : 5308\n"
     ]
    }
   ],
   "source": [
    "# 사용 빈도가 높다고 판단할 등장 회수\n",
    "threshold = 30\n",
    "\n",
    "total_cnt = len(tokenizer.word_index)\n",
    "rare_cnt = 0\n",
    "total_freq = 0\n",
    "rare_freq = 0\n",
    "\n",
    "for key, value in tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "    if value < threshold:\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print(\"단어 집합(vocabulary)의 크기 :\", total_cnt)\n",
    "print(f\"등장 빈도가 {threshold}번 미만인 희귀 단어의 수: {rare_cnt}\")\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt) * 100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq) * 100)\n",
    "\n",
    "# 자주 등장하는 단어 집합의 크기\n",
    "vocab_size = total_cnt - rare_cnt + 2\n",
    "print(\"단어 집합의 크기 :\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 단어수: 75336\n",
      "토큰의 크기 : 17307\n"
     ]
    }
   ],
   "source": [
    "# 30회 이상 등장하는 단어만 이용하여 재토큰화 진행\n",
    "tokenizer2 = Tokenizer(oov_token = '<OOV>', num_words = vocab_size)\n",
    "tokenizer2.fit_on_texts(X)\n",
    "print(f\"전체 단어수: {len(tokenizer2.word_index) + 1}\")\n",
    "\n",
    "token_set = tokenizer2.texts_to_sequences(X)\n",
    "print('토큰의 크기 :', len(token_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count\n",
       "0    256\n",
       "1    161\n",
       "2    289\n",
       "3    266\n",
       "4    206"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장별로 몇개의 단어를 포함하고 있는지 확인\n",
    "word_counts = []\n",
    "\n",
    "for s in token_set:\n",
    "    word_counts.append(len(s))\n",
    "\n",
    "count_df = pd.DataFrame({\"count\": word_counts})\n",
    "count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 많은 단어를 사용하는 문장의 단어 수 : 984\n",
      "가장 적은 단어를 사용하는 문장의 단어수 : 62\n"
     ]
    }
   ],
   "source": [
    "# 가장 많은 단어를 사용한 리뷰와 가장 적은 단어를 사용한 리뷰\n",
    "max_word_count = max(word_counts)\n",
    "min_word_count = min(word_counts)\n",
    "print(\"가장 많은 단어를 사용하는 문장의 단어 수 :\", max_word_count)\n",
    "print(\"가장 적은 단어를 사용하는 문장의 단어수 :\", min_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패딩\n",
    "max_word_count = max(word_counts)\n",
    "# max_word_count = 200\n",
    "pad_token_set = pad_sequences(token_set, maxlen=max_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13845, 984) (3462, 984) (13845,) (3462,)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 분할\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(pad_token_set, Y, test_size = 0.2, random_state = 0)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 케라스 학습을 위한 패키지 로드\n",
    "import keras\n",
    "from keras.layers import LSTM, GRU, Dense, Embedding, Dropout\n",
    "from keras.optimizers import Adam, Nadam, RMSprop\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 종속변수 원핫인코딩\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# oh = OneHotEncoder(sparse_output = False)\n",
    "# y_train_oh = oh.fit_transform(y_train.to_numpy().reshape(-1, 1))\n",
    "# y_test_oh = oh.fit_transform(y_test.to_numpy().reshape(-1, 1))\n",
    "# y_train_oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedKappa(keras.metrics.Metric):\n",
    "    def __init__(self, num_classes=6, epsilon=1e-6):\n",
    "        super().__init__(name=\"weighted_kappa\")\n",
    "        self.num_classes = num_classes\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "        label_vec = keras.ops.arange(num_classes, dtype=keras.backend.floatx())\n",
    "        self.row_label_vec = keras.ops.reshape(label_vec, [1, num_classes])\n",
    "        self.col_label_vec = keras.ops.reshape(label_vec, [num_classes, 1])\n",
    "        col_mat = keras.ops.tile(self.col_label_vec, [1, num_classes])\n",
    "        row_mat = keras.ops.tile(self.row_label_vec, [num_classes, 1])\n",
    "        self.weight_mat = (col_mat - row_mat) ** 2\n",
    "\n",
    "        self.numerator = self.add_weight(name=\"numerator\", initializer=\"zeros\")\n",
    "        self.denominator = self.add_weight(name=\"denominator\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, **args):\n",
    "        # revert ordinal regression labels to classification labels\n",
    "        y_true = keras.ops.one_hot(keras.ops.sum(y_true, axis=-1) - 1, 6)\n",
    "        y_pred = keras.ops.one_hot(\n",
    "            keras.ops.sum(keras.ops.cast(y_pred > 0.5, dtype=\"int8\"), axis=-1) - 1, 6\n",
    "        )\n",
    "        # weighted kappa calculation\n",
    "        y_true = keras.ops.cast(y_true, dtype=self.col_label_vec.dtype)\n",
    "        y_pred = keras.ops.cast(y_pred, dtype=self.weight_mat.dtype)\n",
    "        batch_size = keras.ops.shape(y_true)[0]\n",
    "\n",
    "        cat_labels = keras.ops.matmul(y_true, self.col_label_vec)\n",
    "        cat_label_mat = keras.ops.tile(cat_labels, [1, self.num_classes])\n",
    "        row_label_mat = keras.ops.tile(self.row_label_vec, [batch_size, 1])\n",
    "\n",
    "        weight = (cat_label_mat - row_label_mat) ** 2\n",
    "\n",
    "        self.numerator.assign_add(keras.ops.sum(weight * y_pred))\n",
    "        label_dist = keras.ops.sum(y_true, axis=0, keepdims=True)\n",
    "        pred_dist = keras.ops.sum(y_pred, axis=0, keepdims=True)\n",
    "        w_pred_dist = keras.ops.matmul(\n",
    "            self.weight_mat, keras.ops.transpose(pred_dist, [1, 0])\n",
    "        )\n",
    "        self.denominator.assign_add(\n",
    "            keras.ops.sum(keras.ops.matmul(label_dist, w_pred_dist))\n",
    "        )\n",
    "\n",
    "    def result(self):\n",
    "        return 1.0 - keras.ops.divide_no_nan(self.numerator, self.denominator)\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.numerator.assign(0)\n",
    "        self.denominator.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 21:44:03.686201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22433 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:08:00.0, compute capability: 8.6\n",
      "2024-04-26 21:44:03.918989: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# LSTM - 회귀모델\n",
    "model = Sequential([\n",
    "    Embedding(input_dim = vocab_size, output_dim = 64),\n",
    "    LSTM(units = 64, return_sequences = True, dropout = 0.2, recurrent_dropout = 0.2),\n",
    "    LSTM(32),\n",
    "    Dense(1, activation = 'linear')\n",
    "])\n",
    "\n",
    "model.compile(optimizer = Adam(), loss = 'mae', metrics = ['mse', WeightedKappa()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 21:44:06.777610: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 654ms/step - loss: 1.0421 - mse: 2.0381 - weighted_kappa: 0.9694 - val_loss: 0.8055 - val_mse: 1.1210 - val_weighted_kappa: 0.9687 - learning_rate: 0.0010\n",
      "Epoch 2/1000\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 657ms/step - loss: 0.7848 - mse: 1.0811 - weighted_kappa: 0.9687 - val_loss: 0.7986 - val_mse: 1.1078 - val_weighted_kappa: 0.9687 - learning_rate: 0.0010\n",
      "Epoch 3/1000\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 655ms/step - loss: 0.7729 - mse: 0.9981 - weighted_kappa: 0.9687 - val_loss: 0.7904 - val_mse: 1.0248 - val_weighted_kappa: 0.9687 - learning_rate: 0.0010\n",
      "Epoch 4/1000\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 655ms/step - loss: 0.6601 - mse: 0.7394 - weighted_kappa: 0.9687 - val_loss: 0.5818 - val_mse: 0.6411 - val_weighted_kappa: 0.9687 - learning_rate: 0.0010\n",
      "Epoch 5/1000\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 656ms/step - loss: 0.5102 - mse: 0.5268 - weighted_kappa: 0.9687 - val_loss: 0.4922 - val_mse: 0.5057 - val_weighted_kappa: 0.9687 - learning_rate: 0.0010\n",
      "Epoch 6/1000\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 654ms/step - loss: 0.4503 - mse: 0.4744 - weighted_kappa: 0.9687 - val_loss: 0.4729 - val_mse: 0.5030 - val_weighted_kappa: 0.9687 - learning_rate: 0.0010\n",
      "Epoch 7/1000\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 655ms/step - loss: 0.4365 - mse: 0.4585 - weighted_kappa: 0.9687 - val_loss: 0.4606 - val_mse: 0.4935 - val_weighted_kappa: 0.9687 - learning_rate: 0.0010\n",
      "Epoch 8/1000\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m285s\u001b[0m 658ms/step - loss: 0.4220 - mse: 0.4397 - weighted_kappa: 0.9687 - val_loss: 0.4645 - val_mse: 0.5081 - val_weighted_kappa: 0.9687 - learning_rate: 0.0010\n",
      "Epoch 9/1000\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 656ms/step - loss: 0.4033 - mse: 0.4169 - weighted_kappa: 0.9687 - val_loss: 0.4714 - val_mse: 0.5091 - val_weighted_kappa: 0.9687 - learning_rate: 0.0010\n",
      "Epoch 10/1000\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 657ms/step - loss: 0.3957 - mse: 0.4081 - weighted_kappa: 0.9687 - val_loss: 0.4700 - val_mse: 0.5023 - val_weighted_kappa: 0.9687 - learning_rate: 0.0010\n",
      "Epoch 11/1000\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 652ms/step - loss: 0.3923 - mse: 0.4001 - weighted_kappa: 0.9687 - val_loss: 0.4612 - val_mse: 0.5002 - val_weighted_kappa: 0.9687 - learning_rate: 0.0010\n",
      "Epoch 12/1000\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 649ms/step - loss: 0.3717 - mse: 0.3844 - weighted_kappa: 0.9687 - val_loss: 0.4600 - val_mse: 0.5033 - val_weighted_kappa: 0.9687 - learning_rate: 1.0000e-04\n",
      "Epoch 13/1000\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 655ms/step - loss: 0.3611 - mse: 0.3749 - weighted_kappa: 0.9687 - val_loss: 0.4582 - val_mse: 0.5000 - val_weighted_kappa: 0.9687 - learning_rate: 1.0000e-04\n",
      "Epoch 14/1000\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m285s\u001b[0m 658ms/step - loss: 0.3577 - mse: 0.3669 - weighted_kappa: 0.9687 - val_loss: 0.4570 - val_mse: 0.4983 - val_weighted_kappa: 0.9687 - learning_rate: 1.0000e-04\n",
      "Epoch 15/1000\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 650ms/step - loss: 0.3638 - mse: 0.3810 - weighted_kappa: 0.9687 - val_loss: 0.4589 - val_mse: 0.5020 - val_weighted_kappa: 0.9687 - learning_rate: 1.0000e-04\n",
      "Epoch 16/1000\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 654ms/step - loss: 0.3615 - mse: 0.3766 - weighted_kappa: 0.9687 - val_loss: 0.4558 - val_mse: 0.4985 - val_weighted_kappa: 0.9687 - learning_rate: 1.0000e-04\n",
      "Epoch 17/1000\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 653ms/step - loss: 0.3631 - mse: 0.3783 - weighted_kappa: 0.9687 - val_loss: 0.4574 - val_mse: 0.4992 - val_weighted_kappa: 0.9687 - learning_rate: 1.0000e-04\n",
      "Epoch 18/1000\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 649ms/step - loss: 0.3559 - mse: 0.3690 - weighted_kappa: 0.9687 - val_loss: 0.4554 - val_mse: 0.4953 - val_weighted_kappa: 0.9687 - learning_rate: 1.0000e-04\n",
      "Epoch 19/1000\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 648ms/step - loss: 0.3584 - mse: 0.3716 - weighted_kappa: 0.9687 - val_loss: 0.4625 - val_mse: 0.5039 - val_weighted_kappa: 0.9687 - learning_rate: 1.0000e-04\n",
      "Epoch 20/1000\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 655ms/step - loss: 0.3473 - mse: 0.3625 - weighted_kappa: 0.9687 - val_loss: 0.4575 - val_mse: 0.4993 - val_weighted_kappa: 0.9687 - learning_rate: 1.0000e-04\n",
      "Epoch 21/1000\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 653ms/step - loss: 0.3516 - mse: 0.3622 - weighted_kappa: 0.9687 - val_loss: 0.4574 - val_mse: 0.4980 - val_weighted_kappa: 0.9687 - learning_rate: 1.0000e-04\n",
      "Epoch 22/1000\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m285s\u001b[0m 658ms/step - loss: 0.3459 - mse: 0.3610 - weighted_kappa: 0.9687 - val_loss: 0.4566 - val_mse: 0.4962 - val_weighted_kappa: 0.9687 - learning_rate: 1.0000e-04\n",
      "Epoch 23/1000\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 652ms/step - loss: 0.3529 - mse: 0.3663 - weighted_kappa: 0.9687 - val_loss: 0.4562 - val_mse: 0.4983 - val_weighted_kappa: 0.9687 - learning_rate: 1.0000e-05\n",
      "Epoch 24/1000\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 654ms/step - loss: 0.3449 - mse: 0.3578 - weighted_kappa: 0.9687 - val_loss: 0.4569 - val_mse: 0.4990 - val_weighted_kappa: 0.9687 - learning_rate: 1.0000e-05\n",
      "Epoch 25/1000\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 655ms/step - loss: 0.3436 - mse: 0.3565 - weighted_kappa: 0.9687 - val_loss: 0.4570 - val_mse: 0.4995 - val_weighted_kappa: 0.9687 - learning_rate: 1.0000e-05\n",
      "Epoch 26/1000\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 651ms/step - loss: 0.3444 - mse: 0.3572 - weighted_kappa: 0.9687 - val_loss: 0.4571 - val_mse: 0.4991 - val_weighted_kappa: 0.9687 - learning_rate: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs = 1000, callbacks = [\n",
    "    EarlyStopping(patience = 8, restore_best_weights = True),\n",
    "    ReduceLROnPlateau(patience = 4, factor = 0.1, min_lr = 1e-06)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"./data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>Many people have car where they live. The thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>I am a scientist at NASA that is discussing th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>People always wish they had the same technolog...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id                                          full_text\n",
       "0  000d118  Many people have car where they live. The thin...\n",
       "1  000fe60  I am a scientist at NASA that is discussing th...\n",
       "2  001ab80  People always wish they had the same technolog..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 약어, 이메일주소, 태그문등 불필요한 데이터 제거\n",
    "test_reviews = []\n",
    "\n",
    "for i in test['full_text'].values:\n",
    "    # 불용어 처리\n",
    "    source = \" \".join([w for w in i.split() if w not in stopwords])\n",
    "\n",
    "    # 약어 처리\n",
    "    source = contractions.fix(source)\n",
    "\n",
    "    # email 제거\n",
    "    source = re.sub(\n",
    "            r\"\\b[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\\b\", \"\", source\n",
    "        )\n",
    "\n",
    "    # html 태그 제거\n",
    "    source = re.sub(r\"<[^>]*>\", \"\", source)\n",
    "\n",
    "    # url 제거\n",
    "    source = re.sub(\n",
    "            r\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\",\n",
    "            \"\",\n",
    "            source,\n",
    "        )\n",
    "\n",
    "    # 숫자 제거\n",
    "    source = re.sub(r\"\\b[0-9]+\\b\", \"\", source)\n",
    "\n",
    "    # 특수문자 제거\n",
    "    x = re.sub(r\"[^\\w ]+\", \"\", source)\n",
    "    source = \" \".join(x.split())\n",
    "    \n",
    "    test_reviews.append(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>pp_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>Many people have car where they live. The thin...</td>\n",
       "      <td>Many people car live The thing know use car al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>I am a scientist at NASA that is discussing th...</td>\n",
       "      <td>I scientist NASA discussing face mars I explai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>People always wish they had the same technolog...</td>\n",
       "      <td>People always wish technology seen movies best...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id                                          full_text  \\\n",
       "0  000d118  Many people have car where they live. The thin...   \n",
       "1  000fe60  I am a scientist at NASA that is discussing th...   \n",
       "2  001ab80  People always wish they had the same technolog...   \n",
       "\n",
       "                                             pp_text  \n",
       "0  Many people car live The thing know use car al...  \n",
       "1  I scientist NASA discussing face mars I explai...  \n",
       "2  People always wish technology seen movies best...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['pp_text'] = test_reviews\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test['pp_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_token_set = tokenizer2.texts_to_sequences(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패딩\n",
    "# max_word_count = 200\n",
    "test_pad_token_set = pad_sequences(test_token_set, maxlen=max_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.9913626],\n",
       "       [3.0068352],\n",
       "       [4.0231557]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_pad_token_set)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame()\n",
    "submit['essay_id'] = test['essay_id']\n",
    "submit['score'] = pred.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv(\"./submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
