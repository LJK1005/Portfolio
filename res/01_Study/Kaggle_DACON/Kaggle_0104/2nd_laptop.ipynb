{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import plotly.express as px\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataStorage:\n",
    "    root = \"C:/Users/yjg10/OneDrive/문서/Kaggle_data/Energy\"\n",
    "\n",
    "    data_cols = [\n",
    "        \"target\",\n",
    "        \"county\",\n",
    "        \"is_business\",\n",
    "        \"product_type\",\n",
    "        \"is_consumption\",\n",
    "        \"datetime\",\n",
    "        \"row_id\",\n",
    "    ]\n",
    "    client_cols = [\n",
    "        \"product_type\",\n",
    "        \"county\",\n",
    "        \"eic_count\",\n",
    "        \"installed_capacity\",\n",
    "        \"is_business\",\n",
    "        \"date\",\n",
    "    ]\n",
    "    gas_prices_cols = [\"forecast_date\", \"lowest_price_per_mwh\", \"highest_price_per_mwh\"]\n",
    "    electricity_prices_cols = [\"forecast_date\", \"euros_per_mwh\"]\n",
    "    forecast_weather_cols = [\n",
    "        \"latitude\",\n",
    "        \"longitude\",\n",
    "        \"hours_ahead\",\n",
    "        \"temperature\",\n",
    "        \"dewpoint\",\n",
    "        \"cloudcover_high\",\n",
    "        \"cloudcover_low\",\n",
    "        \"cloudcover_mid\",\n",
    "        \"cloudcover_total\",\n",
    "        \"10_metre_u_wind_component\",\n",
    "        \"10_metre_v_wind_component\",\n",
    "        \"forecast_datetime\",\n",
    "        \"direct_solar_radiation\",\n",
    "        \"surface_solar_radiation_downwards\",\n",
    "        \"snowfall\",\n",
    "        \"total_precipitation\",\n",
    "    ]\n",
    "    historical_weather_cols = [\n",
    "        \"datetime\",\n",
    "        \"temperature\",\n",
    "        \"dewpoint\",\n",
    "        \"rain\",\n",
    "        \"snowfall\",\n",
    "        \"surface_pressure\",\n",
    "        \"cloudcover_total\",\n",
    "        \"cloudcover_low\",\n",
    "        \"cloudcover_mid\",\n",
    "        \"cloudcover_high\",\n",
    "        \"windspeed_10m\",\n",
    "        \"winddirection_10m\",\n",
    "        \"shortwave_radiation\",\n",
    "        \"direct_solar_radiation\",\n",
    "        \"diffuse_radiation\",\n",
    "        \"latitude\",\n",
    "        \"longitude\",\n",
    "    ]\n",
    "    location_cols = [\"longitude\", \"latitude\", \"county\"]\n",
    "    target_cols = [\n",
    "        \"target\",\n",
    "        \"county\",\n",
    "        \"is_business\",\n",
    "        \"product_type\",\n",
    "        \"is_consumption\",\n",
    "        \"datetime\",\n",
    "    ]\n",
    "\n",
    "    def __init__(self):\n",
    "        self.df_data = pl.read_csv(\n",
    "            os.path.join(self.root, \"train.csv\"),\n",
    "            columns=self.data_cols,\n",
    "            try_parse_dates=True,\n",
    "        )\n",
    "        self.df_client = pl.read_csv(\n",
    "            os.path.join(self.root, \"client.csv\"),\n",
    "            columns=self.client_cols,\n",
    "            try_parse_dates=True,\n",
    "        )\n",
    "        self.df_gas_prices = pl.read_csv(\n",
    "            os.path.join(self.root, \"gas_prices.csv\"),\n",
    "            columns=self.gas_prices_cols,\n",
    "            try_parse_dates=True,\n",
    "        )\n",
    "        self.df_electricity_prices = pl.read_csv(\n",
    "            os.path.join(self.root, \"electricity_prices.csv\"),\n",
    "            columns=self.electricity_prices_cols,\n",
    "            try_parse_dates=True,\n",
    "        )\n",
    "        self.df_forecast_weather = pl.read_csv(\n",
    "            os.path.join(self.root, \"forecast_weather.csv\"),\n",
    "            columns=self.forecast_weather_cols,\n",
    "            try_parse_dates=True,\n",
    "        )\n",
    "        self.df_historical_weather = pl.read_csv(\n",
    "            os.path.join(self.root, \"historical_weather.csv\"),\n",
    "            columns=self.historical_weather_cols,\n",
    "            try_parse_dates=True,\n",
    "        )\n",
    "        self.df_weather_station_to_county_mapping = pl.read_csv(\n",
    "            os.path.join(self.root, \"weather_station_to_county_mapping.csv\"),\n",
    "            columns=self.location_cols,\n",
    "            try_parse_dates=True,\n",
    "        )\n",
    "        self.df_data = self.df_data.filter(\n",
    "            pl.col(\"datetime\") >= pd.to_datetime(\"2022-01-01\")\n",
    "        )\n",
    "        self.df_target = self.df_data.select(self.target_cols)\n",
    "\n",
    "        self.schema_data = self.df_data.schema\n",
    "        self.schema_client = self.df_client.schema\n",
    "        self.schema_gas_prices = self.df_gas_prices.schema\n",
    "        self.schema_electricity_prices = self.df_electricity_prices.schema\n",
    "        self.schema_forecast_weather = self.df_forecast_weather.schema\n",
    "        self.schema_historical_weather = self.df_historical_weather.schema\n",
    "        self.schema_target = self.df_target.schema\n",
    "\n",
    "        self.df_weather_station_to_county_mapping = (\n",
    "            self.df_weather_station_to_county_mapping.with_columns(\n",
    "                pl.col(\"latitude\").cast(pl.datatypes.Float32),\n",
    "                pl.col(\"longitude\").cast(pl.datatypes.Float32),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def update_with_new_data(\n",
    "        self,\n",
    "        df_new_client,\n",
    "        df_new_gas_prices,\n",
    "        df_new_electricity_prices,\n",
    "        df_new_forecast_weather,\n",
    "        df_new_historical_weather,\n",
    "        df_new_target,\n",
    "    ):\n",
    "        df_new_client = pl.from_pandas(\n",
    "            df_new_client[self.client_cols], schema_overrides=self.schema_client\n",
    "        )\n",
    "        df_new_gas_prices = pl.from_pandas(\n",
    "            df_new_gas_prices[self.gas_prices_cols],\n",
    "            schema_overrides=self.schema_gas_prices,\n",
    "        )\n",
    "        df_new_electricity_prices = pl.from_pandas(\n",
    "            df_new_electricity_prices[self.electricity_prices_cols],\n",
    "            schema_overrides=self.schema_electricity_prices,\n",
    "        )\n",
    "        df_new_forecast_weather = pl.from_pandas(\n",
    "            df_new_forecast_weather[self.forecast_weather_cols],\n",
    "            schema_overrides=self.schema_forecast_weather,\n",
    "        )\n",
    "        df_new_historical_weather = pl.from_pandas(\n",
    "            df_new_historical_weather[self.historical_weather_cols],\n",
    "            schema_overrides=self.schema_historical_weather,\n",
    "        )\n",
    "        df_new_target = pl.from_pandas(\n",
    "            df_new_target[self.target_cols], schema_overrides=self.schema_target\n",
    "        )\n",
    "\n",
    "        self.df_client = pl.concat([self.df_client, df_new_client]).unique(\n",
    "            [\"date\", \"county\", \"is_business\", \"product_type\"]\n",
    "        )\n",
    "        self.df_gas_prices = pl.concat([self.df_gas_prices, df_new_gas_prices]).unique(\n",
    "            [\"forecast_date\"]\n",
    "        )\n",
    "        self.df_electricity_prices = pl.concat(\n",
    "            [self.df_electricity_prices, df_new_electricity_prices]\n",
    "        ).unique([\"forecast_date\"])\n",
    "        self.df_forecast_weather = pl.concat(\n",
    "            [self.df_forecast_weather, df_new_forecast_weather]\n",
    "        ).unique([\"forecast_datetime\", \"latitude\", \"longitude\", \"hours_ahead\"])\n",
    "        self.df_historical_weather = pl.concat(\n",
    "            [self.df_historical_weather, df_new_historical_weather]\n",
    "        ).unique([\"datetime\", \"latitude\", \"longitude\"])\n",
    "        self.df_target = pl.concat([self.df_target, df_new_target]).unique(\n",
    "            [\"datetime\", \"county\", \"is_business\", \"product_type\", \"is_consumption\"]\n",
    "        )\n",
    "\n",
    "    def preprocess_test(self, df_test):\n",
    "        df_test = df_test.rename(columns={\"prediction_datetime\": \"datetime\"})\n",
    "        df_test = pl.from_pandas(\n",
    "            df_test[self.data_cols[1:]], schema_overrides=self.schema_data\n",
    "        )\n",
    "        return df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesGenerator:\n",
    "    def __init__(self, data_storage):\n",
    "        self.data_storage = data_storage\n",
    "\n",
    "    def _add_general_features(self, df_features):\n",
    "        df_features = (\n",
    "            df_features.with_columns(\n",
    "                pl.col(\"datetime\").dt.ordinal_day().alias(\"dayofyear\"),\n",
    "                pl.col(\"datetime\").dt.hour().alias(\"hour\"),\n",
    "                pl.col(\"datetime\").dt.day().alias(\"day\"),\n",
    "                pl.col(\"datetime\").dt.weekday().alias(\"weekday\"),\n",
    "                pl.col(\"datetime\").dt.month().alias(\"month\"),\n",
    "                pl.col(\"datetime\").dt.year().alias(\"year\"),\n",
    "            )\n",
    "            .with_columns(\n",
    "                pl.concat_str(\n",
    "                    \"county\",\n",
    "                    \"is_business\",\n",
    "                    \"product_type\",\n",
    "                    \"is_consumption\",\n",
    "                    separator=\"_\",\n",
    "                ).alias(\"segment\"),\n",
    "            )\n",
    "            .with_columns(\n",
    "                (np.pi * pl.col(\"dayofyear\") / 183).sin().alias(\"sin(dayofyear)\"),\n",
    "                (np.pi * pl.col(\"dayofyear\") / 183).cos().alias(\"cos(dayofyear)\"),\n",
    "                (np.pi * pl.col(\"hour\") / 12).sin().alias(\"sin(hour)\"),\n",
    "                (np.pi * pl.col(\"hour\") / 12).cos().alias(\"cos(hour)\"),\n",
    "            )\n",
    "        )\n",
    "        return df_features\n",
    "\n",
    "    def _add_client_features(self, df_features):\n",
    "        df_client = self.data_storage.df_client\n",
    "\n",
    "        df_features = df_features.join(\n",
    "            df_client.with_columns(\n",
    "                (pl.col(\"date\") + pl.duration(days=2)).cast(pl.Date)\n",
    "            ),\n",
    "            on=[\"county\", \"is_business\", \"product_type\", \"date\"],\n",
    "            how=\"left\",\n",
    "        )\n",
    "        return df_features\n",
    "\n",
    "    def _add_forecast_weather_features(self, df_features):\n",
    "        df_forecast_weather = self.data_storage.df_forecast_weather\n",
    "        df_weather_station_to_county_mapping = (\n",
    "            self.data_storage.df_weather_station_to_county_mapping\n",
    "        )\n",
    "\n",
    "        df_forecast_weather = (\n",
    "            df_forecast_weather.rename({\"forecast_datetime\": \"datetime\"})\n",
    "            .filter((pl.col(\"hours_ahead\") >= 22) & pl.col(\"hours_ahead\") <= 45)\n",
    "            .drop(\"hours_ahead\")\n",
    "            .with_columns(\n",
    "                pl.col(\"latitude\").cast(pl.datatypes.Float32),\n",
    "                pl.col(\"longitude\").cast(pl.datatypes.Float32),\n",
    "            )\n",
    "            .join(\n",
    "                df_weather_station_to_county_mapping,\n",
    "                how=\"left\",\n",
    "                on=[\"longitude\", \"latitude\"],\n",
    "            )\n",
    "            .drop(\"longitude\", \"latitude\")\n",
    "        )\n",
    "\n",
    "        df_forecast_weather_date = (\n",
    "            df_forecast_weather.group_by(\"datetime\").mean().drop(\"county\")\n",
    "        )\n",
    "\n",
    "        df_forecast_weather_local = (\n",
    "            df_forecast_weather.filter(pl.col(\"county\").is_not_null())\n",
    "            .group_by(\"county\", \"datetime\")\n",
    "            .mean()\n",
    "        )\n",
    "\n",
    "        for hours_lag in [0, 7 * 24]:\n",
    "            df_features = df_features.join(\n",
    "                df_forecast_weather_date.with_columns(\n",
    "                    pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n",
    "                ),\n",
    "                on=\"datetime\",\n",
    "                how=\"left\",\n",
    "                suffix=f\"_forecast_{hours_lag}h\",\n",
    "            )\n",
    "            df_features = df_features.join(\n",
    "                df_forecast_weather_local.with_columns(\n",
    "                    pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n",
    "                ),\n",
    "                on=[\"county\", \"datetime\"],\n",
    "                how=\"left\",\n",
    "                suffix=f\"_forecast_local_{hours_lag}h\",\n",
    "            )\n",
    "\n",
    "        return df_features\n",
    "\n",
    "    def _add_historical_weather_features(self, df_features):\n",
    "        df_historical_weather = self.data_storage.df_historical_weather\n",
    "        df_weather_station_to_county_mapping = (\n",
    "            self.data_storage.df_weather_station_to_county_mapping\n",
    "        )\n",
    "\n",
    "        df_historical_weather = (\n",
    "            df_historical_weather.with_columns(\n",
    "                pl.col(\"latitude\").cast(pl.datatypes.Float32),\n",
    "                pl.col(\"longitude\").cast(pl.datatypes.Float32),\n",
    "            )\n",
    "            .join(\n",
    "                df_weather_station_to_county_mapping,\n",
    "                how=\"left\",\n",
    "                on=[\"longitude\", \"latitude\"],\n",
    "            )\n",
    "            .drop(\"longitude\", \"latitude\")\n",
    "        )\n",
    "\n",
    "        df_historical_weather_date = (\n",
    "            df_historical_weather.group_by(\"datetime\").mean().drop(\"county\")\n",
    "        )\n",
    "\n",
    "        df_historical_weather_local = (\n",
    "            df_historical_weather.filter(pl.col(\"county\").is_not_null())\n",
    "            .group_by(\"county\", \"datetime\")\n",
    "            .mean()\n",
    "        )\n",
    "\n",
    "        for hours_lag in [2 * 24, 7 * 24]:\n",
    "            df_features = df_features.join(\n",
    "                df_historical_weather_date.with_columns(\n",
    "                    pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n",
    "                ),\n",
    "                on=\"datetime\",\n",
    "                how=\"left\",\n",
    "                suffix=f\"_historical_{hours_lag}h\",\n",
    "            )\n",
    "            df_features = df_features.join(\n",
    "                df_historical_weather_local.with_columns(\n",
    "                    pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n",
    "                ),\n",
    "                on=[\"county\", \"datetime\"],\n",
    "                how=\"left\",\n",
    "                suffix=f\"_historical_local_{hours_lag}h\",\n",
    "            )\n",
    "\n",
    "        for hours_lag in [1 * 24]:\n",
    "            df_features = df_features.join(\n",
    "                df_historical_weather_date.with_columns(\n",
    "                    pl.col(\"datetime\") + pl.duration(hours=hours_lag),\n",
    "                    pl.col(\"datetime\").dt.hour().alias(\"hour\"),\n",
    "                )\n",
    "                .filter(pl.col(\"hour\") <= 10)\n",
    "                .drop(\"hour\"),\n",
    "                on=\"datetime\",\n",
    "                how=\"left\",\n",
    "                suffix=f\"_historical_{hours_lag}h\",\n",
    "            )\n",
    "\n",
    "        return df_features\n",
    "\n",
    "    def _add_target_features(self, df_features):\n",
    "        df_target = self.data_storage.df_target\n",
    "\n",
    "        df_target_all_type_sum = (\n",
    "            df_target.group_by([\"datetime\", \"county\", \"is_business\", \"is_consumption\"])\n",
    "            .sum()\n",
    "            .drop(\"product_type\")\n",
    "        )\n",
    "\n",
    "        df_target_all_county_type_sum = (\n",
    "            df_target.group_by([\"datetime\", \"is_business\", \"is_consumption\"])\n",
    "            .sum()\n",
    "            .drop(\"product_type\", \"county\")\n",
    "        )\n",
    "\n",
    "        for hours_lag in [\n",
    "            2 * 24,\n",
    "            3 * 24,\n",
    "            4 * 24,\n",
    "            5 * 24,\n",
    "            6 * 24,\n",
    "            7 * 24,\n",
    "            8 * 24,\n",
    "            9 * 24,\n",
    "            10 * 24,\n",
    "            11 * 24,\n",
    "            12 * 24,\n",
    "            13 * 24,\n",
    "            14 * 24,\n",
    "        ]:\n",
    "            df_features = df_features.join(\n",
    "                df_target.with_columns(\n",
    "                    pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n",
    "                ).rename({\"target\": f\"target_{hours_lag}h\"}),\n",
    "                on=[\n",
    "                    \"county\",\n",
    "                    \"is_business\",\n",
    "                    \"product_type\",\n",
    "                    \"is_consumption\",\n",
    "                    \"datetime\",\n",
    "                ],\n",
    "                how=\"left\",\n",
    "            )\n",
    "\n",
    "        for hours_lag in [2 * 24, 3 * 24, 7 * 24, 14 * 24]:\n",
    "            df_features = df_features.join(\n",
    "                df_target_all_type_sum.with_columns(\n",
    "                    pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n",
    "                ).rename({\"target\": f\"target_all_type_sum_{hours_lag}h\"}),\n",
    "                on=[\"county\", \"is_business\", \"is_consumption\", \"datetime\"],\n",
    "                how=\"left\",\n",
    "            )\n",
    "\n",
    "            df_features = df_features.join(\n",
    "                df_target_all_county_type_sum.with_columns(\n",
    "                    pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n",
    "                ).rename({\"target\": f\"target_all_county_type_sum_{hours_lag}h\"}),\n",
    "                on=[\"is_business\", \"is_consumption\", \"datetime\"],\n",
    "                how=\"left\",\n",
    "                suffix=f\"_all_county_type_sum_{hours_lag}h\",\n",
    "            )\n",
    "\n",
    "        cols_for_stats = [\n",
    "            f\"target_{hours_lag}h\" for hours_lag in [2 * 24, 3 * 24, 4 * 24, 5 * 24]\n",
    "        ]\n",
    "        df_features = df_features.with_columns(\n",
    "            df_features.select(cols_for_stats).mean(axis=1).alias(f\"target_mean\"),\n",
    "            df_features.select(cols_for_stats)\n",
    "            .transpose()\n",
    "            .std()\n",
    "            .transpose()\n",
    "            .to_series()\n",
    "            .alias(f\"target_std\"),\n",
    "        )\n",
    "\n",
    "        for target_prefix, lag_nominator, lag_denomonator in [\n",
    "            (\"target\", 24 * 7, 24 * 14),\n",
    "            (\"target\", 24 * 2, 24 * 9),\n",
    "            (\"target\", 24 * 3, 24 * 10),\n",
    "            (\"target\", 24 * 2, 24 * 3),\n",
    "            (\"target_all_type_sum\", 24 * 2, 24 * 3),\n",
    "            (\"target_all_type_sum\", 24 * 7, 24 * 14),\n",
    "            (\"target_all_county_type_sum\", 24 * 2, 24 * 3),\n",
    "            (\"target_all_county_type_sum\", 24 * 7, 24 * 14),\n",
    "        ]:\n",
    "            df_features = df_features.with_columns(\n",
    "                (\n",
    "                    pl.col(f\"{target_prefix}_{lag_nominator}h\")\n",
    "                    / (pl.col(f\"{target_prefix}_{lag_denomonator}h\") + 1e-3)\n",
    "                ).alias(f\"{target_prefix}_ratio_{lag_nominator}_{lag_denomonator}\")\n",
    "            )\n",
    "\n",
    "        return df_features\n",
    "\n",
    "    def _reduce_memory_usage(self, df_features):\n",
    "        df_features = df_features.with_columns(pl.col(pl.Float64).cast(pl.Float32))\n",
    "        return df_features\n",
    "\n",
    "    def _drop_columns(self, df_features):\n",
    "        df_features = df_features.drop(\n",
    "            \"date\", \"datetime\", \"hour\", \"dayofyear\"\n",
    "        )\n",
    "        return df_features\n",
    "\n",
    "    def _to_pandas(self, df_features, y):\n",
    "        cat_cols = [\n",
    "            \"county\",\n",
    "            \"is_business\",\n",
    "            \"product_type\",\n",
    "            \"is_consumption\",\n",
    "            \"segment\",\n",
    "        ]\n",
    "\n",
    "        if y is not None:\n",
    "            df_features = pd.concat([df_features.to_pandas(), y.to_pandas()], axis=1)\n",
    "        else:\n",
    "            df_features = df_features.to_pandas()\n",
    "\n",
    "        df_features = df_features.set_index(\"row_id\")\n",
    "        df_features[cat_cols] = df_features[cat_cols].astype(\"category\")\n",
    "\n",
    "        return df_features\n",
    "\n",
    "    def generate_features(self, df_prediction_items):\n",
    "        if \"target\" in df_prediction_items.columns:\n",
    "            df_prediction_items, y = (\n",
    "                df_prediction_items.drop(\"target\"),\n",
    "                df_prediction_items.select(\"target\"),\n",
    "            )\n",
    "        else:\n",
    "            y = None\n",
    "\n",
    "        df_features = df_prediction_items.with_columns(\n",
    "            pl.col(\"datetime\").cast(pl.Date).alias(\"date\"),\n",
    "        )\n",
    "\n",
    "        for add_features in [\n",
    "            self._add_general_features,\n",
    "            self._add_client_features,\n",
    "            self._add_forecast_weather_features,\n",
    "            self._add_historical_weather_features,\n",
    "            self._add_target_features,\n",
    "            self._reduce_memory_usage,\n",
    "            self._drop_columns,\n",
    "        ]:\n",
    "            df_features = add_features(df_features)\n",
    "\n",
    "        df_features = self._to_pandas(df_features, y)\n",
    "\n",
    "        return df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_storage = DataStorage()\n",
    "features_generator = FeaturesGenerator(data_storage=data_storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_features = features_generator.generate_features(data_storage.df_data)\n",
    "df_train_features = df_train_features[df_train_features['target'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holidays\n",
    "import datetime\n",
    "\n",
    "estonian_holidays = holidays.country_holidays('EE', years=range(2021, 2026))\n",
    "estonian_holidays = list(estonian_holidays.keys())\n",
    "\n",
    "def add_holidays_as_binary_features(df):\n",
    "    df['country_holiday'] = df.apply(lambda row: (datetime.date(row['year'], row['month'], row['day']) in estonian_holidays) * 1, axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_train_features = add_holidays_as_binary_features(df_train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_ratio = (df_train_features.isnull().sum()/len(df_train_features)).sort_values(ascending = False)\n",
    "null_much = list(null_ratio[null_ratio > 0.5].index)\n",
    "df_train_features.drop(null_much, axis = 1, inplace = True)\n",
    "(df_train_features.isnull().sum()/len(df_train_features)).sort_values(ascending = False)\n",
    "df_med = df_train_features.median(axis = 0, numeric_only = True)\n",
    "\n",
    "cols = df_train_features.select_dtypes(['int64', 'float64', 'float32', 'int8', 'int32']).columns\n",
    "for i in cols:\n",
    "    df_train_features[i] = df_train_features[i].fillna(df_med[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>is_business</th>\n",
       "      <th>product_type</th>\n",
       "      <th>is_consumption</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>segment</th>\n",
       "      <th>sin(dayofyear)</th>\n",
       "      <th>...</th>\n",
       "      <th>target_ratio_168_336</th>\n",
       "      <th>target_ratio_48_216</th>\n",
       "      <th>target_ratio_72_240</th>\n",
       "      <th>target_ratio_48_72</th>\n",
       "      <th>target_all_type_sum_ratio_48_72</th>\n",
       "      <th>target_all_type_sum_ratio_168_336</th>\n",
       "      <th>target_all_county_type_sum_ratio_48_72</th>\n",
       "      <th>target_all_county_type_sum_ratio_168_336</th>\n",
       "      <th>target</th>\n",
       "      <th>country_holiday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>366048</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>0_0_1_0</td>\n",
       "      <td>0.017166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.945753</td>\n",
       "      <td>0.946264</td>\n",
       "      <td>0.946073</td>\n",
       "      <td>0.953341</td>\n",
       "      <td>0.981667</td>\n",
       "      <td>0.983894</td>\n",
       "      <td>0.998563</td>\n",
       "      <td>1.004637</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366049</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>0_0_1_1</td>\n",
       "      <td>0.017166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.945753</td>\n",
       "      <td>0.946264</td>\n",
       "      <td>0.946073</td>\n",
       "      <td>0.953341</td>\n",
       "      <td>0.981667</td>\n",
       "      <td>0.983894</td>\n",
       "      <td>0.998563</td>\n",
       "      <td>1.004637</td>\n",
       "      <td>442.226</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366050</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>0_0_2_0</td>\n",
       "      <td>0.017166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.945753</td>\n",
       "      <td>0.946264</td>\n",
       "      <td>0.946073</td>\n",
       "      <td>0.953341</td>\n",
       "      <td>0.981667</td>\n",
       "      <td>0.983894</td>\n",
       "      <td>0.998563</td>\n",
       "      <td>1.004637</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366051</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>0_0_2_1</td>\n",
       "      <td>0.017166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.945753</td>\n",
       "      <td>0.946264</td>\n",
       "      <td>0.946073</td>\n",
       "      <td>0.953341</td>\n",
       "      <td>0.981667</td>\n",
       "      <td>0.983894</td>\n",
       "      <td>0.998563</td>\n",
       "      <td>1.004637</td>\n",
       "      <td>44.899</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366052</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>0_0_3_0</td>\n",
       "      <td>0.017166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.945753</td>\n",
       "      <td>0.946264</td>\n",
       "      <td>0.946073</td>\n",
       "      <td>0.953341</td>\n",
       "      <td>0.981667</td>\n",
       "      <td>0.983894</td>\n",
       "      <td>0.998563</td>\n",
       "      <td>1.004637</td>\n",
       "      <td>0.015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 152 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       county is_business product_type is_consumption  day  weekday  month  \\\n",
       "row_id                                                                       \n",
       "366048      0           0            1              0    1        6      1   \n",
       "366049      0           0            1              1    1        6      1   \n",
       "366050      0           0            2              0    1        6      1   \n",
       "366051      0           0            2              1    1        6      1   \n",
       "366052      0           0            3              0    1        6      1   \n",
       "\n",
       "        year  segment  sin(dayofyear)  ...  target_ratio_168_336  \\\n",
       "row_id                                 ...                         \n",
       "366048  2022  0_0_1_0        0.017166  ...              0.945753   \n",
       "366049  2022  0_0_1_1        0.017166  ...              0.945753   \n",
       "366050  2022  0_0_2_0        0.017166  ...              0.945753   \n",
       "366051  2022  0_0_2_1        0.017166  ...              0.945753   \n",
       "366052  2022  0_0_3_0        0.017166  ...              0.945753   \n",
       "\n",
       "        target_ratio_48_216  target_ratio_72_240  target_ratio_48_72  \\\n",
       "row_id                                                                 \n",
       "366048             0.946264             0.946073            0.953341   \n",
       "366049             0.946264             0.946073            0.953341   \n",
       "366050             0.946264             0.946073            0.953341   \n",
       "366051             0.946264             0.946073            0.953341   \n",
       "366052             0.946264             0.946073            0.953341   \n",
       "\n",
       "        target_all_type_sum_ratio_48_72  target_all_type_sum_ratio_168_336  \\\n",
       "row_id                                                                       \n",
       "366048                         0.981667                           0.983894   \n",
       "366049                         0.981667                           0.983894   \n",
       "366050                         0.981667                           0.983894   \n",
       "366051                         0.981667                           0.983894   \n",
       "366052                         0.981667                           0.983894   \n",
       "\n",
       "        target_all_county_type_sum_ratio_48_72  \\\n",
       "row_id                                           \n",
       "366048                                0.998563   \n",
       "366049                                0.998563   \n",
       "366050                                0.998563   \n",
       "366051                                0.998563   \n",
       "366052                                0.998563   \n",
       "\n",
       "        target_all_county_type_sum_ratio_168_336   target  country_holiday  \n",
       "row_id                                                                      \n",
       "366048                                  1.004637    0.000                1  \n",
       "366049                                  1.004637  442.226                1  \n",
       "366050                                  1.004637    0.000                1  \n",
       "366051                                  1.004637   44.899                1  \n",
       "366052                                  1.004637    0.015                1  \n",
       "\n",
       "[5 rows x 152 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>is_business</th>\n",
       "      <th>product_type</th>\n",
       "      <th>is_consumption</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1651902</td>\n",
       "      <td>1651902</td>\n",
       "      <td>1651902</td>\n",
       "      <td>1651902</td>\n",
       "      <td>1651902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>173334</td>\n",
       "      <td>895846</td>\n",
       "      <td>742860</td>\n",
       "      <td>825951</td>\n",
       "      <td>12381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         county  is_business  product_type  is_consumption  segment\n",
       "count   1651902      1651902       1651902         1651902  1651902\n",
       "unique       16            2             4               2      138\n",
       "top           0            1             3               0  0_0_1_0\n",
       "freq     173334       895846        742860          825951    12381"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_features.describe(include = 'category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_cols = ['county', 'is_business', 'product_type', 'is_consumption']\n",
    "df_train_features.drop(del_cols, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_features['datetime'] = 0\n",
    "\n",
    "for i in df_train_features.index:\n",
    "    df_train_features.loc[i, 'datetime'] = dt.datetime(df_train_features['year'][i], df_train_features['month'][i], df_train_features['day'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>segment</th>\n",
       "      <th>sin(dayofyear)</th>\n",
       "      <th>cos(dayofyear)</th>\n",
       "      <th>sin(hour)</th>\n",
       "      <th>cos(hour)</th>\n",
       "      <th>eic_count</th>\n",
       "      <th>...</th>\n",
       "      <th>target_ratio_48_216</th>\n",
       "      <th>target_ratio_72_240</th>\n",
       "      <th>target_ratio_48_72</th>\n",
       "      <th>target_all_type_sum_ratio_48_72</th>\n",
       "      <th>target_all_type_sum_ratio_168_336</th>\n",
       "      <th>target_all_county_type_sum_ratio_48_72</th>\n",
       "      <th>target_all_county_type_sum_ratio_168_336</th>\n",
       "      <th>target</th>\n",
       "      <th>country_holiday</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>366048</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>0_0_1_0</td>\n",
       "      <td>0.017166</td>\n",
       "      <td>0.999853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.946264</td>\n",
       "      <td>0.946073</td>\n",
       "      <td>0.953341</td>\n",
       "      <td>0.981667</td>\n",
       "      <td>0.983894</td>\n",
       "      <td>0.998563</td>\n",
       "      <td>1.004637</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366049</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>0_0_1_1</td>\n",
       "      <td>0.017166</td>\n",
       "      <td>0.999853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.946264</td>\n",
       "      <td>0.946073</td>\n",
       "      <td>0.953341</td>\n",
       "      <td>0.981667</td>\n",
       "      <td>0.983894</td>\n",
       "      <td>0.998563</td>\n",
       "      <td>1.004637</td>\n",
       "      <td>442.226</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366050</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>0_0_2_0</td>\n",
       "      <td>0.017166</td>\n",
       "      <td>0.999853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.946264</td>\n",
       "      <td>0.946073</td>\n",
       "      <td>0.953341</td>\n",
       "      <td>0.981667</td>\n",
       "      <td>0.983894</td>\n",
       "      <td>0.998563</td>\n",
       "      <td>1.004637</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366051</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>0_0_2_1</td>\n",
       "      <td>0.017166</td>\n",
       "      <td>0.999853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.946264</td>\n",
       "      <td>0.946073</td>\n",
       "      <td>0.953341</td>\n",
       "      <td>0.981667</td>\n",
       "      <td>0.983894</td>\n",
       "      <td>0.998563</td>\n",
       "      <td>1.004637</td>\n",
       "      <td>44.899</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366052</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>0_0_3_0</td>\n",
       "      <td>0.017166</td>\n",
       "      <td>0.999853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>739.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.946264</td>\n",
       "      <td>0.946073</td>\n",
       "      <td>0.953341</td>\n",
       "      <td>0.981667</td>\n",
       "      <td>0.983894</td>\n",
       "      <td>0.998563</td>\n",
       "      <td>1.004637</td>\n",
       "      <td>0.015</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 149 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        day  weekday  month  year  segment  sin(dayofyear)  cos(dayofyear)  \\\n",
       "row_id                                                                       \n",
       "366048    1        6      1  2022  0_0_1_0        0.017166        0.999853   \n",
       "366049    1        6      1  2022  0_0_1_1        0.017166        0.999853   \n",
       "366050    1        6      1  2022  0_0_2_0        0.017166        0.999853   \n",
       "366051    1        6      1  2022  0_0_2_1        0.017166        0.999853   \n",
       "366052    1        6      1  2022  0_0_3_0        0.017166        0.999853   \n",
       "\n",
       "        sin(hour)  cos(hour)  eic_count  ...  target_ratio_48_216  \\\n",
       "row_id                                   ...                        \n",
       "366048        0.0        1.0      148.0  ...             0.946264   \n",
       "366049        0.0        1.0      148.0  ...             0.946264   \n",
       "366050        0.0        1.0       16.0  ...             0.946264   \n",
       "366051        0.0        1.0       16.0  ...             0.946264   \n",
       "366052        0.0        1.0      739.0  ...             0.946264   \n",
       "\n",
       "        target_ratio_72_240  target_ratio_48_72  \\\n",
       "row_id                                            \n",
       "366048             0.946073            0.953341   \n",
       "366049             0.946073            0.953341   \n",
       "366050             0.946073            0.953341   \n",
       "366051             0.946073            0.953341   \n",
       "366052             0.946073            0.953341   \n",
       "\n",
       "        target_all_type_sum_ratio_48_72  target_all_type_sum_ratio_168_336  \\\n",
       "row_id                                                                       \n",
       "366048                         0.981667                           0.983894   \n",
       "366049                         0.981667                           0.983894   \n",
       "366050                         0.981667                           0.983894   \n",
       "366051                         0.981667                           0.983894   \n",
       "366052                         0.981667                           0.983894   \n",
       "\n",
       "        target_all_county_type_sum_ratio_48_72  \\\n",
       "row_id                                           \n",
       "366048                                0.998563   \n",
       "366049                                0.998563   \n",
       "366050                                0.998563   \n",
       "366051                                0.998563   \n",
       "366052                                0.998563   \n",
       "\n",
       "        target_all_county_type_sum_ratio_168_336   target  country_holiday  \\\n",
       "row_id                                                                       \n",
       "366048                                  1.004637    0.000                1   \n",
       "366049                                  1.004637  442.226                1   \n",
       "366050                                  1.004637    0.000                1   \n",
       "366051                                  1.004637   44.899                1   \n",
       "366052                                  1.004637    0.015                1   \n",
       "\n",
       "                   datetime  \n",
       "row_id                       \n",
       "366048  2022-01-01 00:00:00  \n",
       "366049  2022-01-01 00:00:00  \n",
       "366050  2022-01-01 00:00:00  \n",
       "366051  2022-01-01 00:00:00  \n",
       "366052  2022-01-01 00:00:00  \n",
       "\n",
       "[5 rows x 149 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_cols = ['day', 'month', 'year']\n",
    "df_train_features.drop(del_cols, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_features['weekday'] = df_train_features['weekday'].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_corr = df_train_features.corr()['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_features['datetime'] = df_train_features['datetime'].astype('datetime64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1651902 entries, 366048 to 2018351\n",
      "Columns: 146 entries, weekday to datetime\n",
      "dtypes: category(2), datetime64[ns](1), float32(140), float64(2), int64(1)\n",
      "memory usage: 950.0 MB\n"
     ]
    }
   ],
   "source": [
    "df_train_features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_features.to_csv(\"C:/Users/yjg10/OneDrive/문서/Kaggle_data/Energy/ref/refined.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df_train_features.pop('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_n = df_train_features.select_dtypes(['float32', 'float64', 'int64']).columns\n",
    "col_o = df_train_features.select_dtypes(['category']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n = df_train_features[col_n]\n",
    "df_o = df_train_features[col_o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n = pd.DataFrame(ss.fit_transform(df_n), columns = col_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_o = pd.get_dummies(df_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n.reset_index(drop = True, inplace = True)\n",
    "df_o.reset_index(drop = True, inplace = True)\n",
    "df_dt = df_train_features['datetime'].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.concat([df_dt, df_n, df_o], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m \u001b[0mTimeSeriesSplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_train_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m     \n",
      "Time Series cross-validator\n",
      "\n",
      "Provides train/test indices to split time series data samples\n",
      "that are observed at fixed time intervals, in train/test sets.\n",
      "In each split, test indices must be higher than before, and thus shuffling\n",
      "in cross validator is inappropriate.\n",
      "\n",
      "This cross-validation object is a variation of :class:`KFold`.\n",
      "In the kth split, it returns first k folds as train set and the\n",
      "(k+1)th fold as test set.\n",
      "\n",
      "Note that unlike standard cross-validation methods, successive\n",
      "training sets are supersets of those that come before them.\n",
      "\n",
      "Read more in the :ref:`User Guide <time_series_split>`.\n",
      "\n",
      ".. versionadded:: 0.18\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "n_splits : int, default=5\n",
      "    Number of splits. Must be at least 2.\n",
      "\n",
      "    .. versionchanged:: 0.22\n",
      "        ``n_splits`` default value changed from 3 to 5.\n",
      "\n",
      "max_train_size : int, default=None\n",
      "    Maximum size for a single training set.\n",
      "\n",
      "test_size : int, default=None\n",
      "    Used to limit the size of the test set. Defaults to\n",
      "    ``n_samples // (n_splits + 1)``, which is the maximum allowed value\n",
      "    with ``gap=0``.\n",
      "\n",
      "    .. versionadded:: 0.24\n",
      "\n",
      "gap : int, default=0\n",
      "    Number of samples to exclude from the end of each train set before\n",
      "    the test set.\n",
      "\n",
      "    .. versionadded:: 0.24\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> import numpy as np\n",
      ">>> from sklearn.model_selection import TimeSeriesSplit\n",
      ">>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]])\n",
      ">>> y = np.array([1, 2, 3, 4, 5, 6])\n",
      ">>> tscv = TimeSeriesSplit()\n",
      ">>> print(tscv)\n",
      "TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None)\n",
      ">>> for i, (train_index, test_index) in enumerate(tscv.split(X)):\n",
      "...     print(f\"Fold {i}:\")\n",
      "...     print(f\"  Train: index={train_index}\")\n",
      "...     print(f\"  Test:  index={test_index}\")\n",
      "Fold 0:\n",
      "  Train: index=[0]\n",
      "  Test:  index=[1]\n",
      "Fold 1:\n",
      "  Train: index=[0 1]\n",
      "  Test:  index=[2]\n",
      "Fold 2:\n",
      "  Train: index=[0 1 2]\n",
      "  Test:  index=[3]\n",
      "Fold 3:\n",
      "  Train: index=[0 1 2 3]\n",
      "  Test:  index=[4]\n",
      "Fold 4:\n",
      "  Train: index=[0 1 2 3 4]\n",
      "  Test:  index=[5]\n",
      ">>> # Fix test_size to 2 with 12 samples\n",
      ">>> X = np.random.randn(12, 2)\n",
      ">>> y = np.random.randint(0, 2, 12)\n",
      ">>> tscv = TimeSeriesSplit(n_splits=3, test_size=2)\n",
      ">>> for i, (train_index, test_index) in enumerate(tscv.split(X)):\n",
      "...     print(f\"Fold {i}:\")\n",
      "...     print(f\"  Train: index={train_index}\")\n",
      "...     print(f\"  Test:  index={test_index}\")\n",
      "Fold 0:\n",
      "  Train: index=[0 1 2 3 4 5]\n",
      "  Test:  index=[6 7]\n",
      "Fold 1:\n",
      "  Train: index=[0 1 2 3 4 5 6 7]\n",
      "  Test:  index=[8 9]\n",
      "Fold 2:\n",
      "  Train: index=[0 1 2 3 4 5 6 7 8 9]\n",
      "  Test:  index=[10 11]\n",
      ">>> # Add in a 2 period gap\n",
      ">>> tscv = TimeSeriesSplit(n_splits=3, test_size=2, gap=2)\n",
      ">>> for i, (train_index, test_index) in enumerate(tscv.split(X)):\n",
      "...     print(f\"Fold {i}:\")\n",
      "...     print(f\"  Train: index={train_index}\")\n",
      "...     print(f\"  Test:  index={test_index}\")\n",
      "Fold 0:\n",
      "  Train: index=[0 1 2 3]\n",
      "  Test:  index=[6 7]\n",
      "Fold 1:\n",
      "  Train: index=[0 1 2 3 4 5]\n",
      "  Test:  index=[8 9]\n",
      "Fold 2:\n",
      "  Train: index=[0 1 2 3 4 5 6 7]\n",
      "  Test:  index=[10 11]\n",
      "\n",
      "Notes\n",
      "-----\n",
      "The training set has size ``i * n_samples // (n_splits + 1)\n",
      "+ n_samples % (n_splits + 1)`` in the ``i`` th split,\n",
      "with a test set of size ``n_samples//(n_splits + 1)`` by default,\n",
      "where ``n_samples`` is the number of samples.\n",
      "\u001b[1;31mFile:\u001b[0m           c:\\users\\yjg10\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\n",
      "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
      "\u001b[1;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "?TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.drop('datetime', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['datetime'] =  pd.to_numeric(df2['datetime']) / 10**18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits = 5, gap = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 MAE : 80.98154087418631\n",
      "fold 1 MAE : 73.85010839911494\n",
      "fold 2 MAE : 49.21523738857073\n",
      "fold 3 MAE : 58.4311694308936\n",
      "fold 4 MAE : 82.13250013260446\n",
      "max_depth : 3, estimators : 300 average MAE : 68.922111245074\n",
      "fold 0 MAE : 77.98795956270433\n",
      "fold 1 MAE : 76.69316824012498\n",
      "fold 2 MAE : 47.910502929999865\n",
      "fold 3 MAE : 47.93731763497343\n",
      "fold 4 MAE : 78.26713641636397\n",
      "max_depth : 5, estimators : 300 average MAE : 65.75921695683331\n",
      "fold 0 MAE : 77.52810609688137\n",
      "fold 1 MAE : 73.92370209910862\n",
      "fold 2 MAE : 48.167232701796195\n",
      "fold 3 MAE : 46.015119371682246\n",
      "fold 4 MAE : 79.02890147901375\n",
      "max_depth : 7, estimators : 300 average MAE : 64.93261234969644\n",
      "fold 0 MAE : 77.47144540904547\n",
      "fold 1 MAE : 71.28483948475908\n",
      "fold 2 MAE : 49.65545433082948\n",
      "fold 3 MAE : 44.32718913868249\n",
      "fold 4 MAE : 78.75376546836202\n",
      "max_depth : 9, estimators : 300 average MAE : 64.29853876633571\n",
      "fold 0 MAE : 78.47335174157426\n",
      "fold 1 MAE : 70.90644522958334\n",
      "fold 2 MAE : 49.36180759135011\n",
      "fold 3 MAE : 46.71987138534364\n",
      "fold 4 MAE : 80.16120234691861\n",
      "max_depth : 11, estimators : 300 average MAE : 65.12453565895399\n",
      "fold 0 MAE : 77.92576905036138\n",
      "fold 1 MAE : 71.94488401599992\n",
      "fold 2 MAE : 49.61294182265843\n",
      "fold 3 MAE : 47.11667968440817\n",
      "fold 4 MAE : 80.04680927363947\n",
      "max_depth : 13, estimators : 300 average MAE : 65.32941676941348\n",
      "fold 0 MAE : 77.11010535362404\n",
      "fold 1 MAE : 70.89585111891084\n",
      "fold 2 MAE : 50.88560550390091\n",
      "fold 3 MAE : 47.40086749559039\n",
      "fold 4 MAE : 82.64144050845218\n",
      "max_depth : 15, estimators : 300 average MAE : 65.78677399609566\n"
     ]
    }
   ],
   "source": [
    "depth = [3, 5, 7, 9, 11, 13, 15]\n",
    "n_esti = [300]\n",
    "\n",
    "for j in depth:\n",
    "    for k in n_esti:\n",
    "        avg = np.array([])\n",
    "        for i, (train_index, test_index) in enumerate(tscv.split(df2)):\n",
    "\n",
    "            x_tr = df2.iloc[train_index, :]\n",
    "            y_tr = Y.iloc[train_index]\n",
    "\n",
    "            x_val = df2.iloc[test_index, :]\n",
    "            y_val = Y.iloc[test_index]\n",
    "\n",
    "            xgb = XGBRegressor(random_state = 0, max_depth = j, n_estimators = k,\n",
    "                               learning_rate = 0.2, subsample = 0.5, colsample_bytree = 0.5,\n",
    "                               eval_metric = 'mae')\n",
    "            xgb.fit(x_tr, y_tr)\n",
    "\n",
    "            mae = mean_absolute_error(y_val, xgb.predict(x_val))\n",
    "            print(f\"fold {i} MAE : {mae}\")\n",
    "            avg = np.append(avg, mae)\n",
    "        print(f\"max_depth : {j}, estimators : {k} average MAE : {avg.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 MAE : 75.72025875241857\n",
      "fold 1 MAE : 68.54943751851908\n",
      "fold 2 MAE : 50.90576992133868\n",
      "fold 3 MAE : 57.723488872399095\n",
      "fold 4 MAE : 85.95184691366464\n",
      "max_depth : 3, estimators : 300 average MAE : 67.77016039566801\n",
      "fold 0 MAE : 71.93508387909478\n",
      "fold 1 MAE : 65.5089694241525\n",
      "fold 2 MAE : 45.90355055523187\n",
      "fold 3 MAE : 46.11468641010669\n",
      "fold 4 MAE : 78.28003495824615\n",
      "max_depth : 5, estimators : 300 average MAE : 61.5484650453664\n",
      "fold 0 MAE : 69.08583481551645\n",
      "fold 1 MAE : 66.32195263591586\n",
      "fold 2 MAE : 45.46371996991175\n",
      "fold 3 MAE : 44.39988797653489\n",
      "fold 4 MAE : 79.85594480462278\n",
      "max_depth : 7, estimators : 300 average MAE : 61.02546804050034\n",
      "fold 0 MAE : 68.57551174452631\n",
      "fold 1 MAE : 63.83024322173762\n",
      "fold 2 MAE : 44.94523856023461\n",
      "fold 3 MAE : 44.19009263186432\n",
      "fold 4 MAE : 76.99425694828425\n",
      "max_depth : 9, estimators : 300 average MAE : 59.70706862132943\n",
      "fold 0 MAE : 70.5683556453778\n",
      "fold 1 MAE : 65.23540188611213\n",
      "fold 2 MAE : 44.516310460312546\n",
      "fold 3 MAE : 44.58014709656504\n",
      "fold 4 MAE : 75.72868180158062\n",
      "max_depth : 11, estimators : 300 average MAE : 60.12577937798962\n",
      "fold 0 MAE : 70.64009210546733\n",
      "fold 1 MAE : 60.365100223071856\n",
      "fold 2 MAE : 44.22449993002929\n",
      "fold 3 MAE : 44.908150677387795\n",
      "fold 4 MAE : 75.73527950210762\n",
      "max_depth : 13, estimators : 300 average MAE : 59.174624487612775\n",
      "fold 0 MAE : 72.54374719632138\n",
      "fold 1 MAE : 62.42031282190195\n",
      "fold 2 MAE : 45.42784458270974\n",
      "fold 3 MAE : 45.72831811417935\n",
      "fold 4 MAE : 77.42756534765155\n",
      "max_depth : 15, estimators : 300 average MAE : 60.70955761255279\n"
     ]
    }
   ],
   "source": [
    "depth = [3, 5, 7, 9, 11, 13, 15]\n",
    "n_esti = [300]\n",
    "\n",
    "for j in depth:\n",
    "    for k in n_esti:\n",
    "        avg = np.array([])\n",
    "        for i, (train_index, test_index) in enumerate(tscv.split(df2)):\n",
    "\n",
    "            x_tr = df2.iloc[train_index, :]\n",
    "            y_tr = Y.iloc[train_index]\n",
    "\n",
    "            x_val = df2.iloc[test_index, :]\n",
    "            y_val = Y.iloc[test_index]\n",
    "\n",
    "            lgbm = LGBMRegressor(random_state = 0, max_depth = j, n_estimators = k, force_row_wise = True,\n",
    "                                 num_leaves = 2**j - 2, verbose = -1)\n",
    "            lgbm.fit(x_tr, y_tr)\n",
    "\n",
    "            mae = mean_absolute_error(y_val, lgbm.predict(x_val))\n",
    "            print(f\"fold {i} MAE : {mae}\")\n",
    "            avg = np.append(avg, mae)\n",
    "        print(f\"max_depth : {j}, estimators : {k} average MAE : {avg.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
