{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff01b60a-680c-4562-97f8-d781bf3060c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast, AdamW\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "474da0b6-e817-4728-a200-41a61f047a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# CUDA 사용 가능 여부 확인\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23e98fb3-3ddf-4a5e-a0bd-064aaded971a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n",
      "644it [00:00, 661.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "data = pd.read_csv('./data/train.csv')\n",
    "\n",
    "# 토크나이저 로드\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained('skt/ko-gpt-trinity-1.2B-v0.5', eos_token='</s>')\n",
    "\n",
    "# 데이터 포맷팅 및 토크나이징\n",
    "formatted_data = []\n",
    "for _, row in tqdm(data.iterrows()):\n",
    "    for q_col in ['질문_1', '질문_2']:\n",
    "        for a_col in ['답변_1', '답변_2', '답변_3', '답변_4', '답변_5']:\n",
    "            # 질문과 답변 쌍을 </s> token으로 연결\n",
    "            input_text = row[q_col] + tokenizer.eos_token + row[a_col]\n",
    "            input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "            formatted_data.append(input_ids)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "292d47b4-5b49-4608-874a-ea35475675ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(51200, 1920)\n",
       "    (wpe): Embedding(1024, 1920)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-23): 24 x GPT2Block(\n",
       "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1920, out_features=51200, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 로드\n",
    "model = GPT2LMHeadModel.from_pretrained('skt/ko-gpt-trinity-1.2B-v0.5')\n",
    "model.to(device) # 모델을 GPU단으로 이동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d1772c9-b687-427c-83ca-f7fdee99c91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 하이퍼파라미터(Hyperparameter) 세팅\n",
    "# 실제 필요에 따라 조정하세요.\n",
    "CFG = {\n",
    "    'LR' : 3e-4, # Learning Rate\n",
    "    'EPOCHS' : 15, # 학습 Epoch\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd53a74a-ff1d-474d-9717-42bd3ad7cab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(51200, 1920)\n",
       "    (wpe): Embedding(1024, 1920)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-23): 24 x GPT2Block(\n",
       "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1920, out_features=51200, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 설정\n",
    "optimizer = AdamW(model.parameters(), lr=CFG['LR'])\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d2f4e1a-811a-4664-bb1e-6e3cd86011cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Avg Loss: 2.0187: 100%|██████████| 6440/6440 [14:37<00:00,  7.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Average Loss: 2.018666441572009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Avg Loss: 0.7985: 100%|██████████| 6440/6440 [14:33<00:00,  7.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20, Average Loss: 0.798454093715604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Avg Loss: 0.3763: 100%|██████████| 6440/6440 [14:33<00:00,  7.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20, Average Loss: 0.3762620992432146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Avg Loss: 0.3386:   1%|          | 55/6440 [00:07<15:28,  6.88it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 14\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# 진행률 표시줄에 평균 손실 업데이트\u001b[39;00m\n\u001b[0;32m     17\u001b[0m progress_bar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Avg Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss \u001b[38;5;241m/\u001b[39m (batch_idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "for epoch in range(CFG['EPOCHS']):\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(enumerate(formatted_data), total=len(formatted_data))\n",
    "    for batch_idx, batch in progress_bar:\n",
    "        # 데이터를 GPU단으로 이동\n",
    "        batch = batch.to(device)\n",
    "        outputs = model(batch, labels=batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # 진행률 표시줄에 평균 손실 업데이트\n",
    "        progress_bar.set_description(f\"Epoch {epoch+1} - Avg Loss: {total_loss / (batch_idx+1):.4f}\")\n",
    "\n",
    "    # 에폭의 평균 손실을 출력\n",
    "    print(f\"Epoch {epoch+1}/{CFG['EPOCHS']}, Average Loss: {total_loss / len(formatted_data)}\")\n",
    "\n",
    "# 모델 저장\n",
    "model.save_pretrained(\"./hansoldeco-kogpt2_2\")\n",
    "tokenizer.save_pretrained(\"./hansoldeco-kogpt2_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1246604c-d4b1-4e27-a9fe-31586b3715ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 Fine-tuned 모델과 토크나이저 불러오기\n",
    "model_dir = \"./hansoldeco-kogpt2_2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_dir)\n",
    "model.to(device)\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(model_dir)\n",
    "\n",
    "# Inference를 위한 test.csv 파일 로드\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "# test.csv의 '질문'에 대한 '답변'을 저장할 리스트\n",
    "preds = []\n",
    "\n",
    "# '질문' 컬럼의 각 질문에 대해 답변 생성\n",
    "for test_question in tqdm(test['질문']):\n",
    "    # 입력 텍스트를 토큰화하고 모델 입력 형태로 변환\n",
    "    input_ids = tokenizer.encode(test_question + tokenizer.eos_token, return_tensors='pt')\n",
    "\n",
    "    # 답변 생성\n",
    "    output_sequences = model.generate(\n",
    "        input_ids=input_ids.to(device),\n",
    "        max_length=300,\n",
    "        temperature=0.9,\n",
    "        top_k=1,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.2,\n",
    "        do_sample=True,\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "\n",
    "    # 생성된 텍스트(답변) 저장\n",
    "    for generated_sequence in output_sequences:\n",
    "        full_text = tokenizer.decode(generated_sequence, skip_special_tokens=False)\n",
    "        # 질문과 답변의 사이를 나타내는 eos_token (</s>)를 찾아, 이후부터 출력\n",
    "        answer_start = full_text.find(tokenizer.eos_token) + len(tokenizer.eos_token)\n",
    "        answer_only = full_text[answer_start:].strip()\n",
    "        answer_only = answer_only.replace('\\n', ' ')\n",
    "        preds.append(answer_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fedb30a-fbd2-4fb6-aad7-4187095d00ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 데이터셋의 모든 질의에 대한 답변으로부터 512 차원의 Embedding Vector 추출\n",
    "# 평가를 위한 Embedding Vector 추출에 활용하는 모델은 'distiluse-base-multilingual-cased-v1' 이므로 반드시 확인해주세요.\n",
    "from sentence_transformers import SentenceTransformer # SentenceTransformer Version 2.2.2\n",
    "\n",
    "# Embedding Vector 추출에 활용할 모델(distiluse-base-multilingual-cased-v1) 불러오기\n",
    "model = SentenceTransformer('distiluse-base-multilingual-cased-v1')\n",
    "\n",
    "# 생성한 모든 응답(답변)으로부터 Embedding Vector 추출\n",
    "pred_embeddings = model.encode(preds)\n",
    "pred_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a467c6-7f31-4582-b76e-df15fc2248ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./data/sample_submission.csv')\n",
    "# 제출 양식 파일(sample_submission.csv)을 활용하여 Embedding Vector로 변환한 결과를 삽입\n",
    "submit.iloc[:,1:] = pred_embeddings\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74f71d7-652d-4ab9-8846-8014a3ae108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리더보드 제출을 위한 csv파일 생성\n",
    "submit.to_csv('./baseline_submit_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761b48a5-39fd-4035-b156-90f1f9258ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a171fa0-4be1-42dd-a061-b792fbdee8a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0a0162-e700-4849-a595-43c86aeb15e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bd4afb-e8a5-4a24-b563-17a65f66cb9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bac0596-e49f-4cea-a53b-2153f4077279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b1eb1c-e1c7-4172-9f88-e6a40fd98ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccc43f2-9782-4140-8e73-3c9e92d45250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8132124d-ba61-43be-bea6-f7b1db3e1124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297da860-d56d-4d4d-96c7-21ec103f7d00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060fad33-5822-44c0-b0bd-e68e24174d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947922c7-b625-4612-976d-dc82146b70f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3b42fb-c552-469e-a332-38d5d9faaad0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14714b32-81a6-49da-a1f3-a7631f9a6c16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
