{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff01b60a-680c-4562-97f8-d781bf3060c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast, AdamW\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "138b1b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Y:\\\\Python\\\\script\\\\Study\\\\Dacon_0201'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"Y:\\Python\\script\\Study\\Dacon_0201\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "474da0b6-e817-4728-a200-41a61f047a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# CUDA 사용 가능 여부 확인\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23e98fb3-3ddf-4a5e-a0bd-064aaded971a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n",
      "644it [00:00, 728.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "data = pd.read_csv('./data/train_2.csv')\n",
    "\n",
    "# 토크나이저 로드\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained('skt/ko-gpt-trinity-1.2B-v0.5', eos_token='</s>')\n",
    "\n",
    "# 데이터 포맷팅 및 토크나이징\n",
    "formatted_data = []\n",
    "for _, row in tqdm(data.iterrows()):\n",
    "    for q_col in ['질문_1', '질문_2']:\n",
    "        for a_col in ['답변_1', '답변_2', '답변_3', '답변_4', '답변_5']:\n",
    "            # 질문과 답변 쌍을 </s> token으로 연결\n",
    "            input_text = row[q_col] + tokenizer.eos_token + row[a_col]\n",
    "            input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "            formatted_data.append(input_ids)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "292d47b4-5b49-4608-874a-ea35475675ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(51200, 1920)\n",
       "    (wpe): Embedding(1024, 1920)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-23): 24 x GPT2Block(\n",
       "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1920, out_features=51200, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 로드\n",
    "model = GPT2LMHeadModel.from_pretrained('skt/ko-gpt-trinity-1.2B-v0.5')\n",
    "model.to(device) # 모델을 GPU단으로 이동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d1772c9-b687-427c-83ca-f7fdee99c91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'LR' : 1e-5, # Learning Rate\n",
    "    'EPOCHS' : 25, # 학습 Epoch\n",
    "    'eps' : 5e-06\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd53a74a-ff1d-474d-9717-42bd3ad7cab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(51200, 1920)\n",
       "    (wpe): Embedding(1024, 1920)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-23): 24 x GPT2Block(\n",
       "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1920, out_features=51200, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 설정\n",
    "optimizer = AdamW(model.parameters(), lr=CFG['LR'], eps = CFG['eps'])\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d2f4e1a-811a-4664-bb1e-6e3cd86011cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Avg Loss: 2.0017: 100%|██████████████████████████████████████████████████| 6440/6440 [13:29<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Average Loss: 2.0017297715041207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Avg Loss: 0.8596: 100%|██████████████████████████████████████████████████| 6440/6440 [13:26<00:00,  7.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25, Average Loss: 0.8595979163909088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Avg Loss: 0.4038: 100%|██████████████████████████████████████████████████| 6440/6440 [12:47<00:00,  8.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25, Average Loss: 0.4037878365441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Avg Loss: 0.2435: 100%|██████████████████████████████████████████████████| 6440/6440 [13:17<00:00,  8.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25, Average Loss: 0.24348242043948484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Avg Loss: 0.1878: 100%|██████████████████████████████████████████████████| 6440/6440 [12:58<00:00,  8.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/25, Average Loss: 0.18784358548665686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Avg Loss: 0.1572: 100%|██████████████████████████████████████████████████| 6440/6440 [13:25<00:00,  7.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25, Average Loss: 0.15715380592289038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Avg Loss: 0.1375: 100%|██████████████████████████████████████████████████| 6440/6440 [12:35<00:00,  8.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25, Average Loss: 0.137523602293544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Avg Loss: 0.1255: 100%|██████████████████████████████████████████████████| 6440/6440 [12:34<00:00,  8.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/25, Average Loss: 0.12554364556241318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Avg Loss: 0.1184: 100%|██████████████████████████████████████████████████| 6440/6440 [12:36<00:00,  8.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25, Average Loss: 0.11837184501968047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Avg Loss: 0.1065:  12%|█████▊                                            | 747/6440 [01:27<11:16,  8.42it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 10 - Avg Loss: 0.1098: 100%|█████████████████████████████████████████████████| 6440/6440 [12:34<00:00,  8.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25, Average Loss: 0.10982159897164435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 - Avg Loss: 0.1058: 100%|█████████████████████████████████████████████████| 6440/6440 [12:36<00:00,  8.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25, Average Loss: 0.10577518163243112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 - Avg Loss: 0.1001: 100%|█████████████████████████████████████████████████| 6440/6440 [12:34<00:00,  8.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25, Average Loss: 0.10013770355600053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 - Avg Loss: 0.0975: 100%|█████████████████████████████████████████████████| 6440/6440 [12:34<00:00,  8.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/25, Average Loss: 0.09752837403023742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 - Avg Loss: 0.0940: 100%|█████████████████████████████████████████████████| 6440/6440 [12:49<00:00,  8.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/25, Average Loss: 0.09400121633698065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 - Avg Loss: 0.0918: 100%|█████████████████████████████████████████████████| 6440/6440 [13:26<00:00,  7.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/25, Average Loss: 0.09178142798037749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 - Avg Loss: 0.0901: 100%|█████████████████████████████████████████████████| 6440/6440 [12:35<00:00,  8.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/25, Average Loss: 0.09010479301836063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 - Avg Loss: 0.0884: 100%|█████████████████████████████████████████████████| 6440/6440 [12:33<00:00,  8.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/25, Average Loss: 0.0884027251905779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 - Avg Loss: 0.0870: 100%|█████████████████████████████████████████████████| 6440/6440 [12:34<00:00,  8.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/25, Average Loss: 0.08697277119148938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 - Avg Loss: 0.0869: 100%|█████████████████████████████████████████████████| 6440/6440 [12:33<00:00,  8.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/25, Average Loss: 0.0868845847373111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 - Avg Loss: 0.0852: 100%|█████████████████████████████████████████████████| 6440/6440 [12:35<00:00,  8.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/25, Average Loss: 0.08518911476032982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 - Avg Loss: 0.0824:  59%|████████████████████████████▉                    | 3810/6440 [07:27<05:43,  7.67it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 21 - Avg Loss: 0.0834: 100%|█████████████████████████████████████████████████| 6440/6440 [12:37<00:00,  8.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/25, Average Loss: 0.08342342945401447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 - Avg Loss: 0.0826: 100%|█████████████████████████████████████████████████| 6440/6440 [12:35<00:00,  8.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/25, Average Loss: 0.08264309931040296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 - Avg Loss: 0.0805: 100%|█████████████████████████████████████████████████| 6440/6440 [12:36<00:00,  8.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/25, Average Loss: 0.08052040838046427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 - Avg Loss: 0.0797: 100%|█████████████████████████████████████████████████| 6440/6440 [12:33<00:00,  8.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25, Average Loss: 0.0797043372326681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 - Avg Loss: 0.0795: 100%|█████████████████████████████████████████████████| 6440/6440 [12:35<00:00,  8.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25, Average Loss: 0.07947264220182326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./hansoldeco-kogpt2_4_2\\\\tokenizer_config.json',\n",
       " './hansoldeco-kogpt2_4_2\\\\special_tokens_map.json',\n",
       " './hansoldeco-kogpt2_4_2\\\\tokenizer.json')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습\n",
    "for epoch in range(CFG['EPOCHS']):\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(enumerate(formatted_data), total=len(formatted_data))\n",
    "    for batch_idx, batch in progress_bar:\n",
    "        batch = batch.to(device)\n",
    "        outputs = model(batch, labels=batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        progress_bar.set_description(f\"Epoch {epoch+1} - Avg Loss: {total_loss / (batch_idx+1):.4f}\")\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{CFG['EPOCHS']}, Average Loss: {total_loss / len(formatted_data)}\")\n",
    "\n",
    "# 모델 저장\n",
    "model.save_pretrained(\"./hansoldeco-kogpt2_4_2\")\n",
    "tokenizer.save_pretrained(\"./hansoldeco-kogpt2_4_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1246604c-d4b1-4e27-a9fe-31586b3715ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 130/130 [06:55<00:00,  3.20s/it]\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"./hansoldeco-kogpt2_4_2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_dir)\n",
    "model.to(device)\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(model_dir)\n",
    "\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "preds = []\n",
    "\n",
    "# '질문' 컬럼의 각 질문에 대해 답변 생성\n",
    "for test_question in tqdm(test['질문']):\n",
    "    input_ids = tokenizer.encode(test_question + tokenizer.eos_token, return_tensors='pt')\n",
    "\n",
    "    # 답변 생성\n",
    "    output_sequences = model.generate(\n",
    "        input_ids=input_ids.to(device),\n",
    "        max_length=300,\n",
    "        temperature=0.9,\n",
    "        top_k=1,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.2,\n",
    "        do_sample=True,\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "\n",
    "    # 생성된 텍스트(답변) 저장\n",
    "    for generated_sequence in output_sequences:\n",
    "        full_text = tokenizer.decode(generated_sequence, skip_special_tokens=False)\n",
    "        answer_start = full_text.find(tokenizer.eos_token) + len(tokenizer.eos_token)\n",
    "        answer_only = full_text[answer_start:].strip()\n",
    "        answer_only = answer_only.replace('\\n', ' ')\n",
    "        preds.append(answer_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fedb30a-fbd2-4fb6-aad7-4187095d00ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130, 512)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test 데이터셋의 모든 질의에 대한 답변으로부터 512 차원의 Embedding Vector 추출\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('distiluse-base-multilingual-cased-v1')\n",
    "\n",
    "pred_embeddings = model.encode(preds)\n",
    "pred_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1a467c6-7f31-4582-b76e-df15fc2248ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vec_0</th>\n",
       "      <th>vec_1</th>\n",
       "      <th>vec_2</th>\n",
       "      <th>vec_3</th>\n",
       "      <th>vec_4</th>\n",
       "      <th>vec_5</th>\n",
       "      <th>vec_6</th>\n",
       "      <th>vec_7</th>\n",
       "      <th>vec_8</th>\n",
       "      <th>...</th>\n",
       "      <th>vec_502</th>\n",
       "      <th>vec_503</th>\n",
       "      <th>vec_504</th>\n",
       "      <th>vec_505</th>\n",
       "      <th>vec_506</th>\n",
       "      <th>vec_507</th>\n",
       "      <th>vec_508</th>\n",
       "      <th>vec_509</th>\n",
       "      <th>vec_510</th>\n",
       "      <th>vec_511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>0.015341</td>\n",
       "      <td>0.019901</td>\n",
       "      <td>0.001819</td>\n",
       "      <td>0.013254</td>\n",
       "      <td>0.128906</td>\n",
       "      <td>-0.038372</td>\n",
       "      <td>0.035526</td>\n",
       "      <td>0.003914</td>\n",
       "      <td>0.012441</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015642</td>\n",
       "      <td>-0.065815</td>\n",
       "      <td>0.011862</td>\n",
       "      <td>-0.020828</td>\n",
       "      <td>-0.025905</td>\n",
       "      <td>0.047072</td>\n",
       "      <td>0.006964</td>\n",
       "      <td>-0.008943</td>\n",
       "      <td>0.021947</td>\n",
       "      <td>0.004232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>-0.019322</td>\n",
       "      <td>0.003211</td>\n",
       "      <td>-0.013877</td>\n",
       "      <td>0.033974</td>\n",
       "      <td>0.097455</td>\n",
       "      <td>-0.017306</td>\n",
       "      <td>0.015203</td>\n",
       "      <td>-0.038989</td>\n",
       "      <td>-0.016788</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023184</td>\n",
       "      <td>-0.030240</td>\n",
       "      <td>0.024912</td>\n",
       "      <td>-0.067202</td>\n",
       "      <td>0.001899</td>\n",
       "      <td>0.023498</td>\n",
       "      <td>-0.004316</td>\n",
       "      <td>-0.058046</td>\n",
       "      <td>0.030207</td>\n",
       "      <td>0.031503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>0.022715</td>\n",
       "      <td>-0.082353</td>\n",
       "      <td>-0.059012</td>\n",
       "      <td>0.023319</td>\n",
       "      <td>0.088409</td>\n",
       "      <td>-0.032240</td>\n",
       "      <td>0.020548</td>\n",
       "      <td>0.027710</td>\n",
       "      <td>0.018195</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029399</td>\n",
       "      <td>-0.040173</td>\n",
       "      <td>0.028294</td>\n",
       "      <td>-0.017319</td>\n",
       "      <td>0.005047</td>\n",
       "      <td>0.023821</td>\n",
       "      <td>-0.010594</td>\n",
       "      <td>-0.023640</td>\n",
       "      <td>0.003697</td>\n",
       "      <td>0.087255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>0.014597</td>\n",
       "      <td>0.010334</td>\n",
       "      <td>0.044874</td>\n",
       "      <td>0.021705</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>-0.021076</td>\n",
       "      <td>-0.076503</td>\n",
       "      <td>-0.035291</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018954</td>\n",
       "      <td>0.023068</td>\n",
       "      <td>0.019846</td>\n",
       "      <td>-0.026382</td>\n",
       "      <td>-0.025583</td>\n",
       "      <td>0.002549</td>\n",
       "      <td>-0.017229</td>\n",
       "      <td>0.019436</td>\n",
       "      <td>-0.025017</td>\n",
       "      <td>0.001964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>-0.003408</td>\n",
       "      <td>-0.019128</td>\n",
       "      <td>-0.011795</td>\n",
       "      <td>0.001567</td>\n",
       "      <td>0.115450</td>\n",
       "      <td>-0.022965</td>\n",
       "      <td>0.047793</td>\n",
       "      <td>0.049827</td>\n",
       "      <td>-0.030380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010959</td>\n",
       "      <td>-0.054748</td>\n",
       "      <td>0.051292</td>\n",
       "      <td>-0.017034</td>\n",
       "      <td>-0.030259</td>\n",
       "      <td>0.010181</td>\n",
       "      <td>0.021290</td>\n",
       "      <td>0.010175</td>\n",
       "      <td>-0.020196</td>\n",
       "      <td>0.073795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 513 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id     vec_0     vec_1     vec_2     vec_3     vec_4     vec_5  \\\n",
       "0  TEST_000  0.015341  0.019901  0.001819  0.013254  0.128906 -0.038372   \n",
       "1  TEST_001 -0.019322  0.003211 -0.013877  0.033974  0.097455 -0.017306   \n",
       "2  TEST_002  0.022715 -0.082353 -0.059012  0.023319  0.088409 -0.032240   \n",
       "3  TEST_003  0.014597  0.010334  0.044874  0.021705  0.022972 -0.021076   \n",
       "4  TEST_004 -0.003408 -0.019128 -0.011795  0.001567  0.115450 -0.022965   \n",
       "\n",
       "      vec_6     vec_7     vec_8  ...   vec_502   vec_503   vec_504   vec_505  \\\n",
       "0  0.035526  0.003914  0.012441  ... -0.015642 -0.065815  0.011862 -0.020828   \n",
       "1  0.015203 -0.038989 -0.016788  ... -0.023184 -0.030240  0.024912 -0.067202   \n",
       "2  0.020548  0.027710  0.018195  ... -0.029399 -0.040173  0.028294 -0.017319   \n",
       "3 -0.076503 -0.035291  0.002525  ... -0.018954  0.023068  0.019846 -0.026382   \n",
       "4  0.047793  0.049827 -0.030380  ...  0.010959 -0.054748  0.051292 -0.017034   \n",
       "\n",
       "    vec_506   vec_507   vec_508   vec_509   vec_510   vec_511  \n",
       "0 -0.025905  0.047072  0.006964 -0.008943  0.021947  0.004232  \n",
       "1  0.001899  0.023498 -0.004316 -0.058046  0.030207  0.031503  \n",
       "2  0.005047  0.023821 -0.010594 -0.023640  0.003697  0.087255  \n",
       "3 -0.025583  0.002549 -0.017229  0.019436 -0.025017  0.001964  \n",
       "4 -0.030259  0.010181  0.021290  0.010175 -0.020196  0.073795  \n",
       "\n",
       "[5 rows x 513 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.read_csv('./data/sample_submission.csv')\n",
    "submit.iloc[:,1:] = pred_embeddings\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f74f71d7-652d-4ab9-8846-8014a3ae108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('./baseline_submit_4_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761b48a5-39fd-4035-b156-90f1f9258ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a171fa0-4be1-42dd-a061-b792fbdee8a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0a0162-e700-4849-a595-43c86aeb15e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bd4afb-e8a5-4a24-b563-17a65f66cb9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bac0596-e49f-4cea-a53b-2153f4077279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b1eb1c-e1c7-4172-9f88-e6a40fd98ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccc43f2-9782-4140-8e73-3c9e92d45250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8132124d-ba61-43be-bea6-f7b1db3e1124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297da860-d56d-4d4d-96c7-21ec103f7d00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060fad33-5822-44c0-b0bd-e68e24174d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947922c7-b625-4612-976d-dc82146b70f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3b42fb-c552-469e-a332-38d5d9faaad0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14714b32-81a6-49da-a1f3-a7631f9a6c16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
