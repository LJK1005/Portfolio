{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a74d2477",
   "metadata": {},
   "source": [
    "# LSTM(Long Short-Term Memory) 구조\n",
    "\n",
    "<img src = \"./img/rnn_lstm.jpg\" width = 500 height = 500>\n",
    "\n",
    "- 단기 기억을 오래 하기 위해 고안되었음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6417c5",
   "metadata": {},
   "source": [
    "<img src = \"./img/lstm.png\" width=500 height = 500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0ba641",
   "metadata": {},
   "source": [
    "- 은닉 상태를 만드는 방법\n",
    "    - output gate layer(출력 게이트)\n",
    "        1. 입력과 이전 타임스텝의 은닉 상태를 가중치에 곱한 후 활성화 함수를 통과시켜 다음 은닉 상태를 만듦\n",
    "            - 이 때 기본 순환층과는 달리 시그모이드 활성화 함수를 사용\n",
    "        2. tanh 활성화 함수를 통과한 값과 곱해져서 은닉 상태를 만듦\n",
    "- LSTM은 순환 되는 상태가 2개\n",
    "    - 은닉 상태(hidden state)\n",
    "    - 셀 상태(cell state)\n",
    "        - 다음 층으로 전달되지 않고 LSTM 셀에서 순환만 되는 값\n",
    "        \n",
    "- 셀 상태를 계산하는 과정\n",
    "    - forget gate layer(삭제 게이트)\n",
    "        - 정보를 제거하는 역할\n",
    "        1. 입력과 은닉 상태를 또 다른 가중치에 곱한 다음 시그모이드 함수를 통과\n",
    "        2. 이전 타임스텝의 셀 상태와 곱하여 새로운 셀 상태를 만듦\n",
    "            - 이 셀 상태가 오른쪽에서 tanh 함수를 통과하여 새로운 은닉 상태를 만드는 데 기여\n",
    "    - input gate layer(입력 게이트)\n",
    "        - 새로운 정보를 셀 상태에 추가\n",
    "        1. 입력과 은닉 상태를 각기 다른 가중치에 곱함\n",
    "        2. 하나는 시그모이드 함수, 하나는 tanh 함수를 통과\n",
    "        3. 두 결과를 곱함\n",
    "        4. 이전 셀 상태와 더함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21123eee",
   "metadata": {},
   "source": [
    "## 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a39f5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77f67d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a4c697c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 세트와 검증 세트로 나누기\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5600c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패딩\n",
    "train_seq = pad_sequences(x_train, maxlen = 100)\n",
    "val_seq = pad_sequences(x_val, maxlen = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3dcb4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM 모델 생성\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(500, 16, input_length = 100))\n",
    "model.add(keras.layers.LSTM(8))\n",
    "model.add(keras.layers.Dense(1, activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88270637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 16)           8000      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 8)                 800       \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8809 (34.41 KB)\n",
      "Trainable params: 8809 (34.41 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ee7c29",
   "metadata": {},
   "source": [
    "- LSTM 셀 파라미터 개수\n",
    "    - ((8 * 8) + (16 * 8) + 8) * 4 = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1bdfd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsprop = keras.optimizers.RMSprop(learning_rate = 1e-4)\n",
    "model.compile(optimizer = rmsprop, loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"./model/best-lstm-model.h5\", save_best_only = True)\n",
    "early_stoppinb_cb = keras.callbacks.EarlyStopping(patience = 3, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c865117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 0.6925 - accuracy: 0.5397"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yjg10\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 8s 22ms/step - loss: 0.6925 - accuracy: 0.5401 - val_loss: 0.6913 - val_accuracy: 0.6012\n",
      "Epoch 2/100\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.6894 - accuracy: 0.6113 - val_loss: 0.6860 - val_accuracy: 0.6618\n",
      "Epoch 3/100\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.6751 - accuracy: 0.6798 - val_loss: 0.6521 - val_accuracy: 0.6844\n",
      "Epoch 4/100\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.6189 - accuracy: 0.7052 - val_loss: 0.6071 - val_accuracy: 0.6922\n",
      "Epoch 5/100\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.5882 - accuracy: 0.7218 - val_loss: 0.5874 - val_accuracy: 0.7090\n",
      "Epoch 6/100\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.5680 - accuracy: 0.7369 - val_loss: 0.5707 - val_accuracy: 0.7250\n",
      "Epoch 7/100\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.5494 - accuracy: 0.7511 - val_loss: 0.5565 - val_accuracy: 0.7340\n",
      "Epoch 8/100\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.5328 - accuracy: 0.7603 - val_loss: 0.5425 - val_accuracy: 0.7440\n",
      "Epoch 9/100\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.5170 - accuracy: 0.7710 - val_loss: 0.5275 - val_accuracy: 0.7530\n",
      "Epoch 10/100\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.5017 - accuracy: 0.7799 - val_loss: 0.5157 - val_accuracy: 0.7550\n",
      "Epoch 11/100\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.4882 - accuracy: 0.7848 - val_loss: 0.5030 - val_accuracy: 0.7652\n",
      "Epoch 12/100\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.4757 - accuracy: 0.7918 - val_loss: 0.4940 - val_accuracy: 0.7696\n",
      "Epoch 13/100\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.4647 - accuracy: 0.7950 - val_loss: 0.4842 - val_accuracy: 0.7748\n",
      "Epoch 14/100\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.4550 - accuracy: 0.8013 - val_loss: 0.4772 - val_accuracy: 0.7768\n",
      "Epoch 15/100\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.4475 - accuracy: 0.8030 - val_loss: 0.4703 - val_accuracy: 0.7808\n",
      "Epoch 16/100\n",
      "140/313 [============>.................] - ETA: 2s - loss: 0.4380 - accuracy: 0.8096"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_seq, y_train, epochs = 100, batch_size = 64,\n",
    "                    validation_data = (val_seq, y_val), callbacks = [checkpoint_cb, early_stoppinb_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914d3416",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history[\"loss\"], label = \"train_loss\")\n",
    "plt.plot(history.history[\"accuracy\"], label = \"train_acc\")\n",
    "plt.plot(history.history[\"val_loss\"], label = \"val_loss\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label = \"val_acc\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d43d14d",
   "metadata": {},
   "source": [
    "# GRU(Grated Recurrent Unit) 구조\n",
    "\n",
    "<img src = \"./img/rnn_lstm_gru.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5017e6",
   "metadata": {},
   "source": [
    "- LSTM을 간소화한 버전\n",
    "- LSTM처럼 셀 상태를 계산하지 않고 은닉 상태 하나만 포함\n",
    "- LSTM보다 가중치가 적기 때문에 계산량이 적지만 성능은 LSTM과 유사함\n",
    "    - 데이터 양이 적을 때는 GRU의 성능이 더 좋고 데이터 양이 많을 때는 LSTM의 성능이 더 좋아지는 경향이 있음\n",
    "    - GRU와 LSTM중 어떤 것이 더 낫다라고 말할 수는 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc5750b",
   "metadata": {},
   "source": [
    "<img src = \"./img/gru.png\" width=500 height=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321123b4",
   "metadata": {},
   "source": [
    "- GRU 셀에는 은닉 상태와 입력에 가중치를 곱하고 절편을 더하는 작은 셀 3개가 들어 있음\n",
    "    - 2개는 시그모이드 활성화 함수를 사용하고 하나는 tanh활성화 함수를 사용\n",
    "- reset_gate\n",
    "    - 셀의 출력이 은닉 상태에 바로 곱해져 삭제 게이트 역할을 수행\n",
    "- update_gate\n",
    "    - 어떤 정보를 얼마만큼 유지하고 어떤 정보를 추가할지 결정하는 역할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b208324e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU 모델 생성\n",
    "model2 = keras.Sequential()\n",
    "model2.add(keras.layers.Embedding(500, 16, input_length = 100))\n",
    "model2.add(keras.layers.GRU(8))\n",
    "model2.add(keras.layers.Dense(1, activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f43094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5c04c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "((16 * 8) + (8 * 8) + 8 + 8) * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe534e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsprop = keras.optimizers.RMSprop(learning_rate = 1e-4)\n",
    "model2.compile(optimizer = rmsprop, loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"./model/best-gru-model.h5\", save_best_only = True)\n",
    "early_stoppinb_cb = keras.callbacks.EarlyStopping(patience = 3, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff01ed21",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model2.fit(train_seq, y_train, epochs = 100, batch_size = 64,\n",
    "                    validation_data = (val_seq, y_val), callbacks = [checkpoint_cb, early_stoppinb_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0883fc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history[\"loss\"], label = \"train_loss\")\n",
    "plt.plot(history.history[\"accuracy\"], label = \"train_acc\")\n",
    "plt.plot(history.history[\"val_loss\"], label = \"val_loss\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label = \"val_acc\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81a91cb",
   "metadata": {},
   "source": [
    "# 순환층에 드롭아웃 적용\n",
    "\n",
    "- 순환층은 자체적으로 드롭아웃 기능을 제공\n",
    "    - SimpleRNN과 LSTM 클래스 모두 dropout 매개변수와 recurrent_dropout 매개변수를 가지고 있음\n",
    "        - dropout : 셀의 입력에 드롭아웃을 적용\n",
    "        - recurrent_dropout : 순환되는 은닉 상태에 드롭아웃을 적용\n",
    "            - 버전에 따라 recurrent_dropout이 GPU를 사용하지 못하는 경우가 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9f6d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = keras.Sequential()\n",
    "model3.add(keras.layers.Embedding(500, 16, input_length = 100))\n",
    "model3.add(keras.layers.LSTM(8, dropout = 0.3))\n",
    "model3.add(keras.layers.Dense(1, activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26e0c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsprop = keras.optimizers.RMSprop(learning_rate = 1e-4)\n",
    "model3.compile(optimizer = rmsprop, loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"./model/best-dropout-model.h5\", save_best_only = True)\n",
    "early_stoppinb_cb = keras.callbacks.EarlyStopping(patience = 3, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba5655c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model3.fit(train_seq, y_train, epochs = 100, batch_size = 64,\n",
    "                    validation_data = (val_seq, y_val), callbacks = [checkpoint_cb, early_stoppinb_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b7835a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history[\"loss\"], label = \"train_loss\")\n",
    "plt.plot(history.history[\"accuracy\"], label = \"train_acc\")\n",
    "plt.plot(history.history[\"val_loss\"], label = \"val_loss\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label = \"val_acc\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddfa606",
   "metadata": {},
   "source": [
    "# 2개의 층을 연결\n",
    "\n",
    "- 순환층을 연결할 때의 주의점\n",
    "    - 순환층의 은닉 상태는 샘플의 마지막 타임스텝에 대한 은닉 상태만 다음 층으로 전달\n",
    "        - 순환층을 쌓게 되면 모든 순환층에 순차 데이터가 필요함\n",
    "        - 앞쪽의 순환층이 모든 타입스텝에 대한 은닉 상태를 출력해야함\n",
    "            - return_sequences 매개변수를 True로 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9388e212",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = keras.Sequential()\n",
    "model4.add(keras.layers.Embedding(500, 16, input_length = 100))\n",
    "model4.add(keras.layers.LSTM(8, dropout = 0.3, return_sequences = True))\n",
    "model4.add(keras.layers.LSTM(8, dropout = 0.3))\n",
    "model4.add(keras.layers.Dense(1, activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715a1e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdadd30b",
   "metadata": {},
   "source": [
    "- 첫 번째 LSTM\n",
    "    - 모든 타임스텝(100개)의 은닉상태를 출력하기 때문에 출력의 크기가 (None, 100, 8)\n",
    "- 두 번째 LSTM\n",
    "    - 마지막 타임스텝의 은닉상태만 출력하기 때문에 출력의 크기가 (None, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758e1b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsprop = keras.optimizers.RMSprop(learning_rate = 1e-4)\n",
    "model4.compile(optimizer = rmsprop, loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"./model/best-2rnn-model.h5\", save_best_only = True)\n",
    "early_stoppinb_cb = keras.callbacks.EarlyStopping(patience = 3, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96df8e4d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model4.fit(train_seq, y_train, epochs = 100, batch_size = 64,\n",
    "                    validation_data = (val_seq, y_val), callbacks = [checkpoint_cb, early_stoppinb_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ab6d69",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history[\"loss\"], label = \"train_loss\")\n",
    "plt.plot(history.history[\"accuracy\"], label = \"train_acc\")\n",
    "plt.plot(history.history[\"val_loss\"], label = \"val_loss\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label = \"val_acc\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4cf600",
   "metadata": {},
   "source": [
    "# best model 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe1f9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq = pad_sequences(x_test, maxlen = 100)\n",
    "rnn_model = keras.models.load_model(\"./model/best-dropout-model.h5\")\n",
    "rnn_model.evaluate(test_seq, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417b212b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
